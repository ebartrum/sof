{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "import sys, os\n",
    "import shutil\n",
    "\n",
    "sys.path.append('..')\n",
    "import util\n",
    "\n",
    "_ROOT_DIR = '/mnt/data/new_disk/chenap/dataset/crop'\n",
    "_OUTPUT_DIR = '/mnt/data/new_disk/chenap/dataset/seg_face_real'\n",
    "\n",
    "if os.path.exists(_OUTPUT_DIR):\n",
    "    shutil.rmtree(_OUTPUT_DIR)\n",
    "\n",
    "os.makedirs(_OUTPUT_DIR)\n",
    "\n",
    "img_fps = sorted(glob(os.path.join(_ROOT_DIR, '*.jpg')))\n",
    "\n",
    "all_instances = set([os.path.basename(x).split('_')[0] for x in img_fps])\n",
    "\n",
    "for iid, ins_id in enumerate(all_instances):\n",
    "    \n",
    "    output_dir = os.path.join(_OUTPUT_DIR, ins_id)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    cam2worlds = {}\n",
    "    cam_int = {}\n",
    "\n",
    "    all_imgs = glob(os.path.join(_ROOT_DIR, '%s_*.jpg'%(ins_id)))\n",
    "    \n",
    "    print('[%s] find %d views'%(ins_id, len(all_imgs)))\n",
    "    \n",
    "    for vid, img_fp in enumerate(all_imgs):\n",
    "        \n",
    "        img_fn = os.path.basename(img_fp)\n",
    "        \n",
    "        cam_params = np.load(img_fp.replace('.jpg', '.npy'), allow_pickle=True).item() \n",
    "        \n",
    "        cam_world = np.linalg.inv(cam_params['extrinsics'])\n",
    "        cam_world[:3, 2] *= -1\n",
    "        cam_world[:3, 1] *= -1\n",
    "                \n",
    "        cam2worlds['seg_%02d.png'%(vid)] = cam_world\n",
    "        cam_int['seg_%02d.png'%(vid)] = cam_params['intrinsic']\n",
    "\n",
    "        shutil.copy(\n",
    "            os.path.join(_ROOT_DIR, 'segmap', img_fn.replace('.jpg', '.png')), \n",
    "            os.path.join(output_dir, 'seg_%02d.png'%(vid)))\n",
    "        shutil.copy(\n",
    "            os.path.join(_ROOT_DIR, 'segmap', img_fn.replace('.jpg', '_vis.png')),\n",
    "            os.path.join(output_dir, 'vis_%02d.png'%(vid)))\n",
    "        \n",
    "        shutil.copy(\n",
    "            img_fp, os.path.join(output_dir, 'render_%02d.png'%(vid)))\n",
    "        shutil.copy(\n",
    "            img_fp.replace('.jpg', '.npy'), os.path.join(output_dir, 'cam_%02d.npy'%(vid)))\n",
    "    \n",
    "    np.save(os.path.join(output_dir, 'cam2world.npy'), cam2worlds)\n",
    "    np.save(os.path.join(output_dir, 'intrinsics.npy'), cam_int)\n",
    "    \n",
    "    print('[%03d/%03d] %s'%(iid+1, len(all_instances), output_dir))\n",
    "    "
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "import sys, os\n",
    "import shutil\n",
    "\n",
    "import cv2\n",
    "\n",
    "sys.path.append('..')\n",
    "import util\n",
    "\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_ROOT_DIR = '/home/anpei/liury/data/facial-data/seg_face_real'\n",
    "\n",
    "_TRGT_HW = 128\n",
    "\n",
    "all_instances = sorted(glob(os.path.join(_ROOT_DIR, '[0-9]*')))\n",
    "print('Total number of instances = ', len(all_instances))\n",
    "\n",
    "cam_int_avg = []\n",
    "cam_pose_r = []\n",
    "cam_center = []\n",
    "\n",
    "for iid, ins_dir in enumerate(all_instances[10:]):\n",
    "    \n",
    "    cam2worlds = np.load(os.path.join(ins_dir, 'cam2world.npy'),  allow_pickle=True).item()\n",
    "    cam2worlds = np.asarray([cam2worlds[key] for key in cam2worlds.keys()])\n",
    "        \n",
    "    cam_ints = np.load(os.path.join(ins_dir, 'intrinsics.npy'),  allow_pickle=True).item()\n",
    "        \n",
    "    img_fp = list(cam_ints.keys())[0]\n",
    "    seg_img = cv2.imread(os.path.join(ins_dir, img_fp), cv2.IMREAD_GRAYSCALE)\n",
    "    height, width = seg_img.shape\n",
    "    \n",
    "    print(cam2worlds[0])\n",
    "    \n",
    "#     util.plot_camera_scene(cam2worlds)\n",
    "#     plt.show()\n",
    "            \n",
    "    cur_cam_center =np.asarray([c2w[:3, 3].T for c2w in cam2worlds])\n",
    "    cur_pose_r = [np.linalg.norm(c2w[:3, 3]) for c2w in cam2worlds]\n",
    "    cur_cam_int = list(cam_ints.values())\n",
    "        \n",
    "    cam_pose_r.extend(cur_pose_r)\n",
    "    cam_int_avg.extend(cur_cam_int)\n",
    "    cam_center.extend(cur_cam_center)\n",
    "    \n",
    "    cur_pose_r = np.asarray(cur_pose_r)\n",
    "    cur_cam_int = np.asarray(cur_cam_int)\n",
    "    \n",
    "    print(np.mean(cur_pose_r, axis=0))\n",
    "    print(np.mean(cur_cam_center, axis=0))\n",
    "    print(np.mean(cur_cam_int, axis=0))\n",
    "    print('[%04d/%04d] =========================================='%(iid, len(all_instances)))\n",
    "    \n",
    "#     break\n",
    "        \n",
    "cam_pose_r = np.asarray(cam_pose_r)\n",
    "cam_int_avg = np.asarray(cam_int_avg)\n",
    "\n",
    "print(cam_pose_r.shape, cam_int_avg.shape)\n",
    "\n",
    "cam_pose_r = np.mean(cam_pose_r, axis=0)\n",
    "cam_center = np.mean(cam_center, axis=0)\n",
    "cam_int_avg = np.mean(cam_int_avg, axis=0)\n",
    "\n",
    "print(cam_pose_r)\n",
    "print(cam_center)\n",
    "print(cam_int_avg)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cam_int = np.eye(4)\n",
    "cam_int[:3, :3] = cam_int_avg\n",
    "\n",
    "np.save(os.path.join(_ROOT_DIR, 'intrinsics_avg.npy'), cam_int)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib widget\n",
    "import util\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cam2worlds = np.asarray([cam2worlds[key] for key in cam2worlds.keys()])\n",
    "util.plot_camera_scene(cam2worlds)\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(np.asarray(cam_int).shape)\n",
    "print(cam_int[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "_ROOT_DIR = '/data/new_disk2/liury/data/facial-data/seg_face_0702'\n",
    "\n",
    "img_fps = glob(os.path.join(_ROOT_DIR, '*', 'seg_vis_*.png'))\n",
    "\n",
    "cam_fps = glob(os.path.join(_ROOT_DIR, '*', 'cameras.npy'))\n",
    "\n",
    "zRange = []\n",
    "\n",
    "for idx, cam_fp in enumerate(cam_fps):\n",
    "#     print('| ', cam_fp)\n",
    "    instance_dir = os.path.dirname(cam_fp)\n",
    "    \n",
    "    cam_params = np.load(cam_fp, allow_pickle=True).item()     \n",
    "    world2cam = cam_params['extrinsics']\n",
    "        \n",
    "    zRange = np.asarray(cam_params['zRange'])\n",
    "    cam2world = [np.linalg.inv(x) for x in world2cam]\n",
    "    cam_int = [cam_params['intrinsic']]*len(cam2world)\n",
    "    \n",
    "    img_fps = ['seg_vis_%02d.png'%(x) for x in range(len(cam2world))]\n",
    "    cam2world = dict(zip(img_fps, cam2world))\n",
    "    cam_int = dict(zip(img_fps, cam_int))\n",
    "      \n",
    "#     print(type(cam_int), type(cam2world))\n",
    "#     print(cam2world['seg_vis_00.png'])\n",
    "#     print(cam_int['seg_vis_00.png'])\n",
    "    \n",
    "#     print(cam2world)\n",
    "    \n",
    "#     print('R = ', np.linalg.norm(cam2world[:3, 3]))\n",
    "    \n",
    "    output_fp = os.path.join(instance_dir, 'cam2world.npy')\n",
    "    np.save(output_fp, cam2world)\n",
    "    \n",
    "    output_fp = os.path.join(instance_dir, 'zRange.npy')\n",
    "    np.save(output_fp, zRange)\n",
    "    \n",
    "    output_fp = os.path.join(instance_dir, 'intrinsics.npy')\n",
    "    np.save(output_fp, cam_int)\n",
    "    \n",
    "    print('[%03d/%03d] %s'%(idx, len(cam_fps), output_fp))"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "zRange = np.asarray(zRange)\n",
    "print('*** zRange = ', zRange.shape)\n",
    "\n",
    "zRange[:, :, 0] = np.min(zRange)\n",
    "zRange[:, :, 1] = np.max(zRange)\n",
    "\n",
    "for idx, cam_fp in enumerate(cam_fps):\n",
    "    output_fp = os.path.join(instance_dir, 'zRange.npy')\n",
    "    np.save(output_fp, zRange[idx])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "_ROOT_DIR = '/data/anpei/facial-data/seg_face_0417'\n",
    "\n",
    "# img_fps = glob(os.path.join(_ROOT_DIR, '*', 'labal_*.png'))\n",
    "\n",
    "# for idx, img_fp in enumerate(img_fps):\n",
    "#     dst_fp = img_fp.replace('labal', 'seg')\n",
    "#     print('[%d/%d]'%(idx, len(img_fps)), img_fp, dst_fp)\n",
    "#     shutil.move(img_fp, dst_fp)\n",
    "\n",
    "zRange = []\n",
    "\n",
    "cam_fps = glob(os.path.join(_ROOT_DIR, '*', 'cameras.npy'))\n",
    "\n",
    "for idx, cam_fp in enumerate(cam_fps):\n",
    "#     print('| ', cam_fp)\n",
    "    instance_dir = os.path.dirname(cam_fp)\n",
    "    cam_params = np.load(cam_fp, allow_pickle=True).item()    \n",
    "    world2cam = cam_params['extrinsics']\n",
    "    \n",
    "#     ins_param = cam_params['instance']\n",
    "    \n",
    "#     print(cam_params.keys(), ins_param.shape)\n",
    "    \n",
    "#     print(world2cam[idx])\n",
    "    \n",
    "#     zRange = np.asarray(cam_params['zRange'])\n",
    "\n",
    "    zRange.append(np.asarray(cam_params['zRange']))\n",
    "\n",
    "    cam_int = np.asarray(cam_params['intrinsic'])\n",
    "#     face_params = np.squeeze(cam_params['instance'])\n",
    "    \n",
    "#     print(zRange)\n",
    "    \n",
    "#     print(cam_int)\n",
    "#     for cam_ext in world2cam:\n",
    "#         print(cam_ext)\n",
    "#         print('----------------------------------')\n",
    "\n",
    "\n",
    "#     cam2world = np.asarray([np.linalg.inv(x) for x in world2cam])    \n",
    "#     output_fp = os.path.join(instance_dir, 'cam2world.npy')\n",
    "#     np.save(output_fp, cam2world)\n",
    "    \n",
    "#     output_fp = os.path.join(instance_dir, 'zRange.npy')\n",
    "#     np.save(output_fp, zRange)\n",
    "    \n",
    "#     output_fp = os.path.join(instance_dir, 'params.npy')\n",
    "#     np.save(output_fp, face_params)\n",
    "    \n",
    "    print('[%03d/%03d] %s'%(idx, len(cam_fps), output_fp))\n",
    "        "
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "zRange = np.asarray(zRange)\n",
    "print('*** zRange = ', zRange.shape)\n",
    "\n",
    "zRange[:, :, 0] = np.min(zRange)\n",
    "zRange[:, :, 1] = np.max(zRange)\n",
    "\n",
    "print(np.unique(zRange))\n",
    "\n",
    "for idx, cam_fp in enumerate(cam_fps):\n",
    "    output_fp = os.path.join(instance_dir, 'zRange.npy')\n",
    "    np.save(output_fp, zRange[idx])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.save('cam2world.npy', np.asarray(cam2world))\n",
    "np.save('extrinsics.npy', np.asarray(world2cam))\n",
    "\n",
    "\n",
    "cc = np.load('cam2world.npy')\n",
    "print(cc[0].shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "img = Image.open(os.path.join('images', '00000_seg_02_04.png'))\n",
    "print(img.size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import glob\n",
    "\n",
    "imgs = sorted(glob.glob(os.path.join('images', '00000_seg_*.png')))\n",
    "print(imgs, len(imgs))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from glob import glob\n",
    "import os\n",
    "tot_imgs = glob(os.path.join('images', '*.png'))\n",
    "tot_imgs = set([os.path.basename(x)[:5] for x in tot_imgs])\n",
    "tot_imgs = [int(x) for x in tot_imgs]\n",
    "\n",
    "print(len(tot_imgs))\n",
    "\n",
    "for x in tot_imgs:\n",
    "    print(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "P = np.load('cam2world.npy')\n",
    "print(P.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "\n",
    "P = np.load('/data/anpei/facial-data/seg_face_8000/cam2world.npy')\n",
    "# print(P[0])\n",
    "\n",
    "for i in range(P.shape[0]):\n",
    "    R = P[0, :3, :3]\n",
    "    T = P[0, :3, 3]\n",
    "\n",
    "    print(np.linalg.det(R), np.linalg.norm(T))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.set_xlim([-1.5,1.5])\n",
    "ax.set_ylim([-1.5,1.5])\n",
    "ax.set_zlim([-1.5,1.5])\n",
    "\n",
    "_r = 1.1165075011366656\n",
    "\n",
    "_v = 1.0\n",
    "_omega = 20\n",
    "\n",
    "t = np.linspace(0, 2, num=100)\n",
    "z = -_r + t * _v\n",
    "\n",
    "r = np.sqrt(_R**2-z**2)\n",
    "x = r * np.cos(_omega * t)\n",
    "y = r * np.sin(_omega * t)\n",
    "\n",
    "ax.plot3D(x, y, z, 'gray')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(x.shape, y.shape, z.shape)\n",
    "_cam_pos = (np.stack([x, y, z])).T\n",
    "print(_cam_poses.shape)\n",
    "\n",
    "_cam_target = np.zeros((1,3))\n",
    "_cam_up = np.asarray([0.0, 1.0, 0.0])\n",
    "\n",
    "CAM_X = []\n",
    "CAM_Y = []\n",
    "CAM_Z = []\n",
    "\n",
    "_cam2world = []\n",
    "\n",
    "for idx in range(10):\n",
    "    cam_pos = _cam_pos[idx, :]\n",
    "    cam_dir = (_cam_target - cam_pos)\n",
    "    cam_dir = cam_dir / np.linalg.norm(cam_dir)\n",
    "    cam_right = np.cross(_cam_up, cam_dir)\n",
    "    cam_right = cam_right / np.linalg.norm(cam_right)\n",
    "    cam_up = np.cross(cam_dir, cam_right)\n",
    "    cam_up = cam_up / np.linalg.norm(cam_up)\n",
    "    \n",
    "    cam_R = np.concatenate([cam_right, cam_up, cam_dir, _cam_target], axis=0)\n",
    "    cam_P = np.ones((4, 1))\n",
    "    cam_P[:3,] = np.expand_dims(cam_pos, 1)\n",
    "        \n",
    "    _cam2world.append(np.concatenate([cam_R, cam_P], axis=1))\n",
    "\n",
    "_cam2world = np.asarray(_cam2world)\n",
    "print(_cam2world.shape)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "# ax.set_xlim([-2.5,1.5])\n",
    "# ax.set_ylim([-1.5,1.5])\n",
    "# ax.set_zlim([-1.5,1.5])\n",
    "\n",
    "ax.quiver(_cam_pos[:, 0],_cam_pos[:, 1],_cam_pos[:, 2], CAM_X[:, 0], CAM_X[:, 1], CAM_X[:, 2], 'red')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "# Make the grid\n",
    "x, y, z = np.meshgrid(CAM_X,\n",
    "                      CAM_Y,\n",
    "                      CAM_Z)\n",
    "\n",
    "# Make the direction data for the arrows\n",
    "u = np.sin(np.pi * x) * np.cos(np.pi * y) * np.cos(np.pi * z)\n",
    "v = -np.cos(np.pi * x) * np.sin(np.pi * y) * np.cos(np.pi * z)\n",
    "w = (np.sqrt(2.0 / 3.0) * np.cos(np.pi * x) * np.cos(np.pi * y) *\n",
    "     np.sin(np.pi * z))\n",
    "\n",
    "print(x.shape, u.shape)\n",
    "\n",
    "ax.quiver(x, y, z, u, v, w, length=0.1, normalize=True)\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import data_util\n",
    "img = data_util.load_gray('/data/anpei/facial-data/seg_face_2000/09667/seg_19.png', sidelength=128)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "print(np.max(img), np.min(img))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import random\n",
    "\n",
    "print(np.random.randint(0, 25, 1)[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from glob import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "\n",
    "_ROOT_DIR = '/data/anpei/facial-data/seg_video/video'\n",
    "img_fps = sorted(glob(os.path.join(_ROOT_DIR, '*.png')))\n",
    "\n",
    "output_dir = os.path.join(_ROOT_DIR, '..', 'fake')\n",
    "\n",
    "bin_size = (len(img_fps) // 25)\n",
    "\n",
    "cams = np.load('/data/anpei/facial-data/seg_video/0000/cams.npy', allow_pickle=True)\n",
    "\n",
    "for idx in range(25):\n",
    "    img_idx = idx*bin_size+np.random.randint(0, bin_size, 1)[0]\n",
    "    \n",
    "    img_fp = img_fps[img_idx]\n",
    "    \n",
    "    cam2world = np.expand_dims(cams[img_idx]['extrinsic'], axis=0)\n",
    "#     cam2world[:3, 3] /= 100.0\n",
    "#     print(np.linalg.det(cam2world[:3, :3]))\n",
    "    \n",
    "    trgt_dir = os.path.join(output_dir, '%04d'%(idx*4+3))\n",
    "    \n",
    "#     os.makedirs(trgt_dir, exist_ok=True)\n",
    "    \n",
    "    trgt_fp = os.path.join(trgt_dir, 'seg_00.png')\n",
    "    \n",
    "    img = cv2.imread(img_fp, cv2.IMREAD_UNCHANGED)\n",
    "    H, W, C = img.shape    \n",
    "    seg = img[:, W//2:, 0]\n",
    "    \n",
    "    cv2.imwrite(trgt_fp, seg)\n",
    "    np.save(os.path.join(trgt_dir, 'cam2world.npy'), cam2world)\n",
    "    \n",
    "    print(im_id, trgt_fp, cam2world.shape, seg.shape)\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "_ROOT_DIR = '/data/anpei/facial-data/seg_video/0000'\n",
    "\n",
    "cam_fp = os.path.join(_ROOT_DIR, 'cams.npy')\n",
    "\n",
    "cam_exts = np.load(cam_fp, allow_pickle=True)\n",
    "\n",
    "for idx, cam in enumerate(list(cam_exts)):\n",
    "    cam_ext = cam['extrinsic']\n",
    "    R_ext = cam_ext[:3, :3]\n",
    "#     print(np.linalg.det(cam_ext))\n",
    "    cam2world = np.linalg.inv(cam['extrinsic'])\n",
    "    f = 1.0\n",
    "    fx, fy = cam['scale']\n",
    "    \n",
    "    \n",
    "#     int_fp = os.path.join('%04d'%)\n",
    "    print(idx, fx, fy)\n",
    "#     print(cam2world.shape, cam['extrinsic'].shape)\n",
    "#     print(cam['extrinsic'])\n",
    "    print(cam2world)\n",
    "#     R = cam2world[:3, :3]\n",
    "#     T = cam2world[:3, 3].T\n",
    "    print(np.linalg.det(R))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "_ROOT_DIR = '/data/anpei/facial-data/seg_face_new/'\n",
    "_OUTPUT_DIR = '/data/anpei/facial-data/seg_video/fake/'\n",
    "ind_idx = glob(os.path.join(_ROOT_DIR, '[0-9]*'))\n",
    "\n",
    "slc_idx = random.choices(ind_idx, k=25)\n",
    "print(len(slc_idx))\n",
    "\n",
    "# transform = torchvision.transforms.RandomAffine(10, )\n",
    "\n",
    "for idx, src in enumerate(slc_idx):\n",
    "    out_dir = os.path.join(_OUTPUT_DIR, '%04d'%(idx*4+2))\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    cam2worlds = np.load(os.path.join(src, 'cam2world.npy'))\n",
    "    \n",
    "    cam_idx = random.choice(list(range(25)))\n",
    "    cam2world = cam2worlds[idx]\n",
    "    cam_R = cam2world[:3, :3]\n",
    "    cam_T = cam2world[:3, 3]\n",
    "    \n",
    "    rot = (R.from_euler('xyz', (np.random.rand(3)-0.5)*10, degrees=True)).as_dcm()\n",
    "    cam2world[:3, :3] = rot.dot(cam_R)\n",
    "    cam2world[:3, 3] = cam_T + (np.random.rand(3)-0.5)*0.2\n",
    "    \n",
    "    cam2world = np.expand_dims(cam2world, axis=0)\n",
    "#     print(cam2world)\n",
    "    \n",
    "    img_fp = os.path.join(src, 'seg_%02d.png'%(cam_idx))\n",
    "    \n",
    "    shutil.copyfile(img_fp, os.path.join(out_dir, 'seg_00.png'))\n",
    "    np.save(os.path.join(out_dir, 'cam2world.npy'), cam2world)\n",
    "    \n",
    "    print(idx, img_fp)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "rot = (R.from_euler('xyz', (np.random.rand(3)-0.5)*10, degrees=True)).as_dcm()\n",
    "\n",
    "# print(dir(rot))\n",
    "# rot = rot.as_matrix()\n",
    "\n",
    "print(rand_rot, rot)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import random\n",
    "_ROOT_DIR = '/data/anpei/facial-data/seg_face_new'\n",
    "_OUTPUT_DIR = '/data/anpei/facial-data/seg_video/0000/'\n",
    "ind_idx = glob(os.path.join(_ROOT_DIR, '[0-9]*'))\n",
    "print(len(ind_idx))\n",
    "\n",
    "slc_ins = random.choices(ind_idx, k=25)\n",
    "print(slc_cams)\n",
    "\n",
    "for ins in slc_ins:\n",
    "    output_dir = os.path.join\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cam_path = '/data/anpei/facial-data/seg_face_2000_depth/09616/cam2world.npy'\n",
    "cam_params = np.load(cam_path)\n",
    "\n",
    "for cam_param in cam_params:\n",
    "    R = cam_param[:3, :3]\n",
    "    print(cam_param)\n",
    "    print(np.linalg.det(R))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "_ROOT_DIR = '/data/anpei/facial-data/seg_video/0000/images'\n",
    "img_dirs = glob(os.path.join(_ROOT_DIR, '[0-9]*'))\n",
    "\n",
    "for img_dir in img_dirs:\n",
    "    print(img_dir)\n",
    "    shutil.copyfile('/data/anpei/facial-data/seg_video/0000/cam2world.npy', os.path.join(img_dir, 'cam2world.npy'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(cams)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cam_fp = os.path.join(_ROOT_DIR, 'cams.npy')\n",
    "cams = np.load(cam_fp, allow_pickle=True)\n",
    "\n",
    "cam2world = np.asarray(\n",
    "    [np.linalg.inv(cam['extrinsic']) for cam in cams], dtype=np.float32)\n",
    "\n",
    "cam2world[:, :3, 3] /= 100.0\n",
    "\n",
    "print(cam2world)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import json\n",
    "import wget\n",
    "import os\n",
    "\n",
    "\n",
    "slc_ctg = ['\"Coats & Outerwear\"', '\"Dresses\"', '\"Sleepwear\"', '\"Shirts & Tops\"', '\"Sweaters\"', ] \n",
    "\n",
    "output_dir = '/data/anpei/facial-data/mvc_fashion'\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "all_urls = []\n",
    "\n",
    "with open('mvc_info.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "    for item in data:\n",
    "         if (item['productGender'] == '\"Womens\"') and (item['category'] in slc_ctg):\n",
    "            all_urls.append(item['image_url_4x'])\n",
    "\n",
    "with open('all_urls.txt', 'w') as f:\n",
    "    f.writelines('\\n'.join(all_urls))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(data[0].keys())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from PIL import Image, ImageOps\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "data_dir = '/data/anpei/facial-data/bag_imgs/images'\n",
    "img_fps = glob(os.path.join(data_dir, '*'))\n",
    "\n",
    "output_dir = '/data/anpei/facial-data/bag_imgs/resized'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(len(img_fps))\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "failed_list = []\n",
    "desired_size = 1024\n",
    "\n",
    "for idx, im_pth in enumerate(img_fps):\n",
    "\n",
    "    try:\n",
    "        im = Image.open(im_pth).convert(\"RGB\")\n",
    "        old_size = im.size  # old_size[0] is in (width, height) format\n",
    "\n",
    "        ratio = float(desired_size)/max(old_size)\n",
    "        new_size = tuple([int(x*ratio) for x in old_size])\n",
    "        # use thumbnail() or resize() method to resize the input image\n",
    "\n",
    "        # thumbnail is a in-place operation\n",
    "\n",
    "        # im.thumbnail(new_size, Image.ANTIALIAS)\n",
    "\n",
    "        im = im.resize(new_size, Image.ANTIALIAS)\n",
    "        # create a new image and paste the resized on it\n",
    "        \n",
    "        \n",
    "        padding = ((desired_size-im.size[0])//2, (desired_size-im.size[1])//2)\n",
    "        new_im = F.pad(im, padding, padding_mode='edge')\n",
    "        new_im = F.center_crop(new_im, desired_size)\n",
    "        \n",
    "        output_fp = os.path.join(output_dir, '%04d.jpg'%(idx))\n",
    "        new_im.save(output_fp)\n",
    "        print('[%d/%d] %s'%(idx, len(img_fps), output_fp), new_im.size)\n",
    "\n",
    "#         plt.imshow(new_im)\n",
    "#         plt.show()\n",
    "        \n",
    "    except:\n",
    "        print(\"Unexpected error:\", sys.exc_info())\n",
    "        failed_list.append(im_pth)\n",
    "\n",
    "print('Failed: ', failed_list)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}