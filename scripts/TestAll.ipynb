{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INIT embedding] variable.\n",
      "[INIT renderer] FC, with renderer = FC\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SOFModel(\n",
       "  (latent_codes): Embedding(221, 256)\n",
       "  (hyper_phi): HyperFC(\n",
       "    (layers): ModuleList(\n",
       "      (0): NewCls(\n",
       "        (hyper_linear): HyperLinear(\n",
       "          (hypo_params): FCBlock(\n",
       "            (net): Sequential(\n",
       "              (0): FCLayer(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                  (2): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): FCLayer(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                  (2): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (norm_nl): Sequential(\n",
       "          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): NewCls(\n",
       "        (hyper_linear): HyperLinear(\n",
       "          (hypo_params): FCBlock(\n",
       "            (net): Sequential(\n",
       "              (0): FCLayer(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                  (2): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): FCLayer(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                  (2): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Linear(in_features=256, out_features=65792, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (norm_nl): Sequential(\n",
       "          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): NewCls(\n",
       "        (hyper_linear): HyperLinear(\n",
       "          (hypo_params): FCBlock(\n",
       "            (net): Sequential(\n",
       "              (0): FCLayer(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                  (2): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): FCLayer(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                  (2): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Linear(in_features=256, out_features=65792, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (norm_nl): Sequential(\n",
       "          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ray_marcher): Raymarcher(\n",
       "    (lstm): Linear(\n",
       "      (linear): ModuleList(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (1): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (2): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (3): Linear(in_features=256, out_features=1, bias=False)\n",
       "      )\n",
       "      (bias): ModuleList(\n",
       "        (0): Linear(in_features=3, out_features=256, bias=True)\n",
       "        (1): Linear(in_features=3, out_features=256, bias=True)\n",
       "        (2): Linear(in_features=3, out_features=256, bias=True)\n",
       "        (3): Linear(in_features=3, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pixel_generator): FCBlock(\n",
       "    (net): Sequential(\n",
       "      (0): FCLayer(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): FCLayer(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): FCLayer(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): Linear(in_features=256, out_features=20, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (l2_loss): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys,os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from modeling import SOFModel\n",
    "from dataset.face_dataset import _campos2matrix\n",
    "\n",
    "import util\n",
    "from sklearn import mixture\n",
    "\n",
    "_RENDERER = 'FC'\n",
    "_ORTHO = False\n",
    "\n",
    "_MODEL_PATH = '../checkpoints/epoch_0250_iter_050000.pth'\n",
    "_OPT_CAM = False\n",
    "_ORTHO = True\n",
    "_TOT_NUM_INSTANCES = 221\n",
    "\n",
    "focal = 36\n",
    "cam_center =  np.asarray([0, 0, 4.5])\n",
    "dpt_range = [2.0, 5.0]\n",
    "\n",
    "_IMG_SIZE = 128\n",
    "_OUT_SIZE = 128\n",
    "_INTERP_STEPS = 20\n",
    "\n",
    "_DEFAULT_CAM_INT = np.array(\n",
    "    [[focal,0,_IMG_SIZE//2],\n",
    "     [0,focal,_IMG_SIZE//2],\n",
    "     [0,0,1]])\n",
    "\n",
    "lookat = np.asarray([0, 0, 0.0])\n",
    "cam_up = np.asarray([0.0, 1.0, 0.0])\n",
    "_DEFAULT_CAM_POSE =  _campos2matrix(cam_center, lookat, cam_up)\n",
    "\n",
    "torch.cuda.set_device(2)\n",
    "\n",
    "model = SOFModel(num_instances=_TOT_NUM_INSTANCES,\n",
    "                  latent_dim=256,\n",
    "                  renderer=_RENDERER,\n",
    "                  tracing_steps=10,\n",
    "                  freeze_networks=True,\n",
    "                  out_channels=20,\n",
    "                  img_sidelength=_IMG_SIZE,\n",
    "                  output_sidelength=_OUT_SIZE,\n",
    "                  opt_cam=_OPT_CAM,\n",
    "                  orthogonal=_ORTHO,\n",
    "                 )\n",
    "\n",
    "util.custom_load(model, path=_MODEL_PATH, discriminator=None,\n",
    "                 overwrite_embeddings=False, overwrite_cam=True)\n",
    "\n",
    "model.eval()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6604c7df8e5a4b17a5d616bf0efb3cf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=136, description='ins_id', max=220), FloatSlider(value=2.0, description=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.volRenderer import render_scene_cam, VolRender, _LABEL, _CMAP\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, IntSlider, FloatSlider\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def render_dpt(ins_id, dpt, vis_cls):\n",
    "    \n",
    "    latent = model.get_embedding({'instance_idx': torch.LongTensor([ins_id]).squeeze().cuda()}).unsqueeze(0)\n",
    "    \n",
    "    out_img, out_seg, prob, dpt_map = render_scene_cam(\n",
    "        model, latent, _DEFAULT_CAM_POSE, _DEFAULT_CAM_INT, _OUT_SIZE, dpt=dpt)\n",
    "    \n",
    "    figure=plt.figure(figsize=(10,5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(out_img)\n",
    "    plt.grid(\"off\");\n",
    "    plt.axis(\"off\");\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"depth\")\n",
    "    plt.imshow(dpt_map)\n",
    "    plt.grid(\"off\");\n",
    "    plt.axis(\"off\");\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(_LABEL[vis_cls])\n",
    "    plt.imshow(prob[:, :, vis_cls], cmap=plt.get_cmap('magma'))\n",
    "    plt.grid(\"off\");\n",
    "    plt.axis(\"off\");\n",
    "\n",
    "\n",
    "dpt_slider = FloatSlider(min=dpt_range[0], max=dpt_range[1], step=0.005)\n",
    "cls_slider = IntSlider(min=0, max=len(_LABEL)-1, step=1, value=0)\n",
    "ins_slider = IntSlider(min=0, max=_TOT_NUM_INSTANCES-1, step=1, value=136)\n",
    "    \n",
    "interactive_plot = interactive(render_dpt, ins_id=ins_slider, dpt=dpt_slider, vis_cls=cls_slider)\n",
    "output = interactive_plot.children[-1]\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = model.get_embedding({'instance_idx': torch.LongTensor([ins_slider.value]).squeeze().cuda()}).unsqueeze(0)\n",
    "_OUT_SIZE = 512\n",
    "renderer = VolRender(\n",
    "    model, z, _DEFAULT_CAM_POSE, _DEFAULT_CAM_INT, dpt_range, \n",
    "    ortho=_ORTHO, level_set=-0.5, resolution=(_OUT_SIZE, _OUT_SIZE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'render_scene_cam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2258632/2797584037.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0mdst_latent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     out_segs,vis_outputs = render_spiral_path(\n\u001b[0m\u001b[1;32m    214\u001b[0m         cam_center,lookat,radii,src_latent,dst_latent, directions=directions)\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2258632/2797584037.py\u001b[0m in \u001b[0;36mrender_spiral_path\u001b[0;34m(cam_center, lookat, radii, src_latent, trgt_latent, directions)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mcam_pose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_campos2matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcam_T\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mout_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_seg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrender_scene_cam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_latent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcam_pose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_DEFAULT_CAM_INT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_OUT_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mvis_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'render_scene_cam' is not defined"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "from scipy.stats import norm\n",
    "from dataset.face_dataset import _campos2matrix\n",
    "\n",
    "remap_list = np.array([0,1,2,2,3,3,4,5,6,7,8,9,9,10,11,12,13,14,15,16]).astype('float')\n",
    "def id_remap(seg):\n",
    "    return remap_list[seg.astype('int')]\n",
    "\n",
    "def vis_condition_img(img):\n",
    "    part_colors = [[0, 0, 0], [127, 212, 255], [255, 255, 127], [255, 255, 170],#'skin',1 'eye_brow'2,  'eye'3\n",
    "                    [240, 157, 240], [255, 212, 255], #'r_nose'4, 'l_nose'5\n",
    "                    [31, 162, 230], [127, 255, 255], [127, 255, 255],#'mouth'6, 'u_lip'7,'l_lip'8\n",
    "                    [0, 255, 85], [0, 255, 170], #'ear'9 'ear_r'10\n",
    "                    [255, 255, 170],\n",
    "                    [127, 170, 255], [85, 0, 255], [255, 170, 127], #'neck'11, 'neck_l'12, 'cloth'13\n",
    "                    [212, 127, 255], [0, 170, 255],#, 'hair'14, 'hat'15\n",
    "                    [255, 255, 0], [255, 255, 85], [255, 255, 170],\n",
    "                    [255, 0, 255], [255, 85, 255], [255, 170, 255],\n",
    "                    [0, 255, 255], [85, 255, 255], [170, 255, 255], [100, 150, 200]]\n",
    "    H,W = img.shape\n",
    "    condition_img_color = np.zeros((H,W,3)).astype('uint8')\n",
    "\n",
    "    num_of_class = int(np.max(img))\n",
    "    for pi in range(1, num_of_class + 1):\n",
    "        index = np.where(img == pi)\n",
    "        condition_img_color[index[0], index[1],:] = part_colors[pi]\n",
    "    return condition_img_color\n",
    "\n",
    "\n",
    "def render_spiral_path(cam_center,lookat,radii,src_latent,trgt_latent, directions=None):\n",
    "    # ROTATE\n",
    "    R = np.linalg.norm(cam_center-lookat) + radii[0]\n",
    "\n",
    "    theta = []\n",
    "    theta_range = [0.0, -0.45, 0.45, 0.0]\n",
    "    for i in range(len(theta_range)-1):\n",
    "        theta.append( np.linspace(theta_range[i],theta_range[i+1], num=_INTERP_STEPS))\n",
    "    theta = np.concatenate(theta)\n",
    "    x = R*np.sin(theta)\n",
    "    y = np.zeros_like(x)\n",
    "    z = R*np.cos(theta)\n",
    "    cam_T = np.stack([x,y,z],axis=1) + lookat.reshape((1,3))\n",
    "\n",
    "    vis_outputs,out_segs = [],[]\n",
    "    for i in range(len(theta)):\n",
    "        cam_pose = _campos2matrix(cam_T[i], lookat)      \n",
    "        out_img, out_seg,_,_ = render_scene_cam(model, src_latent, cam_pose, _DEFAULT_CAM_INT, _OUT_SIZE)  \n",
    "\n",
    "        vis_outputs.append(out_img)\n",
    "        out_segs.append(out_seg)\n",
    "\n",
    "\n",
    "    # SPPIRAL PATH\n",
    "    t = np.linspace(0, 4*np.pi, _INTERP_STEPS*4, endpoint=True)\n",
    "    for k in range(len(t)):\n",
    "        cam_T = np.array([np.cos(t[k]), -np.sin(t[k]), -np.sin(0.5*t[k])]) * radii\n",
    "        cam_T = cam_T[[1,2,0]] + cam_center\n",
    "        cam_pose = _campos2matrix(cam_T, lookat)\n",
    "        out_img, out_seg,_,_ = render_scene_cam(model, src_latent, cam_pose, _DEFAULT_CAM_INT, _OUT_SIZE)  \n",
    "        vis_outputs.append(out_img)\n",
    "        out_segs.append(out_seg)\n",
    "\n",
    "    init_seg = out_seg.copy()\n",
    "    if directions is not None:\n",
    "        mouse_count = np.sum(init_seg==8)\n",
    "        init_seg[(init_seg>=2)*(init_seg<=10)] = 1\n",
    "        \n",
    "        direction = directions[0] if np.sum(mouse_count)<40 else directions[1]\n",
    "    \n",
    "        smile_latent = src_latent.clone()\n",
    "        steps = [0.3/_INTERP_STEPS]*_INTERP_STEPS*2\n",
    "        for j in steps:\n",
    "            smile_latent += j*direction\n",
    "            out_img, out_seg,_,_ = render_scene_cam(model, smile_latent, cam_pose, _DEFAULT_CAM_INT, _OUT_SIZE)  \n",
    "            mask = (out_seg>=2)*(out_seg<=10)\n",
    "            result = np.array(init_seg)\n",
    "            result[mask] = out_seg[mask]\n",
    "            out_segs.append(result)\n",
    "            vis_outputs.append(vis_condition_img(id_remap(result)))\n",
    "            \n",
    "    length = len(out_segs)\n",
    "    for i in range(_INTERP_STEPS*2):\n",
    "        out_segs.append(out_segs[length-i-1])\n",
    "        vis_outputs.append(vis_outputs[length-i-1])\n",
    "        \n",
    "    cdf_scale = 1.0/(1.0-norm.cdf(-_INTERP_STEPS,0,6)*2)\n",
    "    for idx in range(-_INTERP_STEPS,_INTERP_STEPS+1):\n",
    "        \n",
    "        _w = (norm.cdf(idx,0,6)-norm.cdf(-_INTERP_STEPS,0,6))*cdf_scale\n",
    "        latent = (1.0-_w)*src_latent + _w*trgt_latent\n",
    "        \n",
    "        out_img, out_seg,_,_ = render_scene_cam(model, latent, cam_pose, _DEFAULT_CAM_INT, _OUT_SIZE) \n",
    "        vis_outputs.append(out_img)\n",
    "        out_segs.append(out_seg)\n",
    "\n",
    "    length = len(out_segs)\n",
    "    for i in range(_INTERP_STEPS*2):\n",
    "        out_segs.append(out_segs[length-i-1])\n",
    "        vis_outputs.append(vis_outputs[length-i-1])\n",
    "        \n",
    "\n",
    "    return out_segs,vis_outputs\n",
    "\n",
    "\n",
    "def render_spiral_path_withDepth(render, src_latent, trgt_latent=None, dst_latent=None, directions=None):\n",
    "    # ROTATE\n",
    "    R = np.linalg.norm(cam_center-lookat) + radii[0]\n",
    "\n",
    "    theta = []\n",
    "    theta_range = [0.0, -0.55, 0.55, 0.0]\n",
    "    for i in range(len(theta_range)-1):\n",
    "        theta.append( np.linspace(theta_range[i],theta_range[i+1], num=_INTERP_STEPS))\n",
    "\n",
    "    theta = np.concatenate(theta)\n",
    "    x = R*np.sin(theta)\n",
    "    y = np.zeros_like(x)\n",
    "    z = R*np.cos(theta)\n",
    "    cam_T = np.stack([x,y,z],axis=1) + lookat.reshape((1,3))\n",
    "\n",
    "    vis_outputs,out_segs = [],[]\n",
    "    for i in range(len(theta)):\n",
    "        cam_pose = _campos2matrix(cam_T[i], lookat)        \n",
    "        _, out_img_with_init, _, out_seg_with_init, _, _, _ = renderer.render(cam_pose, _DEFAULT_CAM_INT, resolution=[_IMG_SIZE, _IMG_SIZE])\n",
    "\n",
    "        vis_outputs.append(out_img_with_init)\n",
    "        out_segs.append(out_seg_with_init)\n",
    "\n",
    "\n",
    "    # SPPIRAL PATH\n",
    "    t = np.linspace(0, 4*np.pi, _INTERP_STEPS*4, endpoint=True)\n",
    "    for k in range(len(t)):\n",
    "        cam_T = np.array([np.cos(t[k]), -np.sin(t[k]), -np.sin(0.5*t[k])]) * radii\n",
    "        cam_T = cam_T[[1,2,0]] + cam_center\n",
    "        cam_pose = _campos2matrix(cam_T, lookat)\n",
    "        _, out_img_with_init, _, out_seg_with_init, _, _, _ = renderer.render(cam_pose, _DEFAULT_CAM_INT, resolution=[_IMG_SIZE, _IMG_SIZE])\n",
    "\n",
    "        vis_outputs.append(out_img_with_init)\n",
    "        out_segs.append(out_seg_with_init)\n",
    "\n",
    "    init_seg = out_seg_with_init.copy()\n",
    "    if directions is not None:\n",
    "        mouse_count = np.sum(init_seg==8)\n",
    "        out_seg_with_init[(init_seg>=2)*(init_seg<=10)] = 1\n",
    "        \n",
    "        direction = directions[0] if np.sum(mouse_count)<40 else directions[1]\n",
    "    \n",
    "        smile_latent = src_latent.clone()\n",
    "        steps = [0.3/_INTERP_STEPS]*_INTERP_STEPS*2 \n",
    "        for j in steps:\n",
    "            smile_latent += j*direction\n",
    "            render = VolRender(model, smile_latent, _DEFAULT_CAM_POSE, _DEFAULT_CAM_INT, dpt_range, \n",
    "                ortho=_ORTHO, level_set=-0.5, resolution=(_OUT_SIZE, _OUT_SIZE))\n",
    "            \n",
    "            _, out_img_with_init, _, out_seg_with_init, _, _, _ = renderer.render(cam_pose, _DEFAULT_CAM_INT, resolution=[_IMG_SIZE, _IMG_SIZE])\n",
    "            mask = (out_seg_with_init>=2)*(out_seg_with_init<=10)\n",
    "            result = np.array(init_seg)\n",
    "            result[mask] = out_seg_with_init[mask]\n",
    "            out_segs.append(result)\n",
    "            \n",
    "            vis_outputs.append(vis_condition_img(id_remap(result)))\n",
    "    \n",
    "    length = len(out_segs)\n",
    "    for i in range(_INTERP_STEPS*2):\n",
    "        out_segs.append(out_segs[length-i-1])\n",
    "        vis_outputs.append(vis_outputs[length-i-1])\n",
    "        \n",
    "    cdf_scale = 1.0/(1.0-norm.cdf(-_INTERP_STEPS,0,6)*2)\n",
    "    for idx in range(-_INTERP_STEPS,_INTERP_STEPS+1):\n",
    "        \n",
    "        _w = (norm.cdf(idx,0,6)-norm.cdf(-_INTERP_STEPS,0,6))*cdf_scale\n",
    "        latent = (1.0-_w)*src_latent + _w*trgt_latent\n",
    "        \n",
    "        render = VolRender(model, latent, _DEFAULT_CAM_POSE, _DEFAULT_CAM_INT, dpt_range, \n",
    "                ortho=_ORTHO, level_set=-0.5, resolution=(_OUT_SIZE, _OUT_SIZE))\n",
    "            \n",
    "        _, out_img_with_init, _, out_seg_with_init, _, _, _ = renderer.render(cam_pose, _DEFAULT_CAM_INT, resolution=[_IMG_SIZE, _IMG_SIZE])\n",
    "        vis_outputs.append(out_img_with_init)\n",
    "        out_segs.append(out_seg_with_init)\n",
    "        \n",
    "\n",
    "    length = len(out_segs)\n",
    "    for i in range(_INTERP_STEPS*2):\n",
    "        out_segs.append(out_segs[length-i-1])\n",
    "        vis_outputs.append(vis_outputs[length-i-1])\n",
    "        \n",
    "    return out_segs,vis_outputs\n",
    "\n",
    "_OUT_SIZE = 128\n",
    "_IMG_SIZE = 128\n",
    "\n",
    "lookat = np.asarray([0, 0.1, 0.0])\n",
    "cam_center =  np.asarray([0, 0.1, 4.5])\n",
    "cam_up = np.asarray([0.0, 1.0, 0.0])\n",
    "# radii, focus_depth = np.asarray([0.1, 0.12, 4.5]), 10 # z,x,y\n",
    "radii, focus_depth = np.asarray([0.5,0.6,0.5]), 4.5 # z,x,y\n",
    "\n",
    "num_comp = 16\n",
    "gmm = mixture.GaussianMixture(\n",
    "    n_components=num_comp, covariance_type='full')\n",
    "gmm.fit(model.latent_codes.weight.data.cpu().numpy())\n",
    "\n",
    "_LOG_ROOT = '../log/mv'\n",
    "smile_dir = torch.from_numpy(np.load('../checkpoints/MicrosoftAzure/happiness_dir.npy')).float()\n",
    "neutral_dir = torch.from_numpy(np.load('../checkpoints/MicrosoftAzure/neutral_dir.npy')).float()\n",
    "directions = torch.stack((smile_dir,neutral_dir),dim=0)\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    print(i)\n",
    "    src_latent = torch.from_numpy(gmm.sample(1)[0]).float()\n",
    "    dst_latent = torch.from_numpy(gmm.sample(1)[0]).float()\n",
    "\n",
    "    out_segs,vis_outputs = render_spiral_path(\n",
    "        cam_center,lookat,radii,src_latent,dst_latent, directions=directions)\n",
    "    \n",
    "    # save data\n",
    "    os.makedirs(os.path.join(_LOG_ROOT, '%03d'%i),exist_ok=True)\n",
    "    os.makedirs(os.path.join(_LOG_ROOT, 'vis'),exist_ok=True)\n",
    "    for k,out_seg in enumerate(out_segs):\n",
    "        output_fp = os.path.join(_LOG_ROOT, '%03d'%i,'%03d.png'%k)\n",
    "        util.write_img(out_seg, output_fp)\n",
    "    \n",
    "    vis_fp = output_fp = os.path.join(_LOG_ROOT, 'vis','%03d.gif'%i)\n",
    "    imageio.mimsave(vis_fp, vis_outputs, fps=15.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.from_numpy(np.load('/home/anpei/Jack12/MicrosoftAzure/happiness_dir.npy')).float().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = model.get_embedding({'instance_idx': torch.LongTensor([91]).squeeze().cuda()}).unsqueeze(0)\n",
    "_OUT_SIZE = 256\n",
    "dpt_range = [0.83,1.15]\n",
    "_DEFAULT_CAM_INT = np.array([[400*_OUT_SIZE/128,0,_OUT_SIZE//2],[0,400*_OUT_SIZE/128,_OUT_SIZE//2],[0,0,1]])\n",
    "renderer = VolRender(\n",
    "    model, z, _DEFAULT_CAM_POSE, _DEFAULT_CAM_INT, dpt_range, \n",
    "    ortho=_ORTHO, level_set=-0.5, resolution=(_OUT_SIZE, _OUT_SIZE))\n",
    "p = mp.plot(renderer.world_v, renderer.f, 1.0-renderer.color,return_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_steps = np.linspace(1.1,3.0, num=8)\n",
    "for i,d in enumerate(depth_steps):\n",
    "    cam_center =  np.asarray([0, 0.0, d])\n",
    "    _DEFAULT_CAM_INT = np.array([[400*_OUT_SIZE/128+200*i,0,_OUT_SIZE//2],[0,400*_OUT_SIZE/128+200*i,_OUT_SIZE//2],[0,0,1]])\n",
    "    cam_P = _campos2matrix(cam_center, lookat)   \n",
    "\n",
    "    out_seg, out_seg_with_init, pred_dpt, pred_dpt_with_init, depth_piror = renderer.render(cam_P, _DEFAULT_CAM_INT, resolution=[_OUT_SIZE, _OUT_SIZE])\n",
    "    depth_piror[depth_piror==0] = 10\n",
    "    \n",
    "    depth = np.concatenate((pred_dpt, pred_dpt_with_init, depth_piror),axis=1)\n",
    "    depth_min, depth_max = np.min(depth[depth>0]), np.max(depth[depth>0])\n",
    "    depth = (depth-cam_center[2]+0.25)/0.3\n",
    "    depth_image = np.round(depth*255).astype('uint8')\n",
    "    depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=1.0), cv2.COLORMAP_JET)\n",
    "    \n",
    "    result = np.concatenate((out_seg,out_seg_with_init,depth_colormap),axis=1)\n",
    "    cv2.imwrite('/home/anpei/Desktop/softgan_test/result/our_marching_cube_%03d.png'%i,result[...,::-1])\n",
    "#     plt.imshow(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 1.1\n",
    "theta = []\n",
    "theta_range = [-1.0, 1.0]\n",
    "for i in range(len(theta_range)-1):\n",
    "    theta.append( np.linspace(theta_range[i],theta_range[i+1], num=5, endpoint=True))\n",
    "theta = np.concatenate(theta)\n",
    "x = R*np.sin(theta)\n",
    "y = np.zeros_like(x)\n",
    "z = R*np.cos(theta)\n",
    "cam_T = np.stack([x,y,z],axis=1) + lookat.reshape((1,3))\n",
    "_DEFAULT_CAM_INT = np.array([[450*_OUT_SIZE/128,0,_OUT_SIZE//2],[0,450*_OUT_SIZE/128,_OUT_SIZE//2],[0,0,1]])\n",
    "\n",
    "vis_outputs = []\n",
    "for i in range(len(theta)):\n",
    "    cam_P = _campos2matrix(cam_T[i], lookat)   \n",
    "    out_seg, out_seg_with_init, pred_dpt, pred_dpt_with_init, depth_piror = renderer.render(cam_P, _DEFAULT_CAM_INT, resolution=[_OUT_SIZE, _OUT_SIZE])\n",
    "\n",
    "    cv2.imwrite('/home/anpei/Desktop/softgan_test/result/our_segmap_%03d.png'%i,out_seg[...,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_P = _campos2matrix(cam_T[0], lookat)   \n",
    "render_cam_P = np.array(cam_P)\n",
    "render_cam_P[:,2] = -render_cam_P[:,2]\n",
    "render_cam_P = np.linalg.inv(render_cam_P)\n",
    "render_cam_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh,pyrender\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def renderDepth_ortho(mesh,cam=np.eye(4),model=np.eye(4),scale=[1,1],resolution=[720,1280]):\n",
    "\n",
    "    obj = pyrender.Mesh.from_trimesh(mesh, smooth=False)\n",
    "\n",
    "    scene = pyrender.Scene(ambient_light=[1.0, 1.0, 1.0], bg_color=[0, 0, 0])\n",
    "    camera = pyrender.OrthographicCamera(xmag=1, ymag=resolution[1]/2/scale[1], znear=1e-3, zfar=10000.0)\n",
    "    light = pyrender.DirectionalLight(color=[1.0, 1.0, 1.0], intensity=2.0)\n",
    "\n",
    "    scene.add(obj, pose=  model)\n",
    "    scene.add(light, pose=  model)\n",
    "    scene.add(camera, pose = cam)\n",
    "    \n",
    "    # render scene\n",
    "    r = pyrender.OffscreenRenderer(resolution[1], resolution[0])\n",
    "    color, depth = r.render(scene)\n",
    "    \n",
    "    return color, depth\n",
    "\n",
    "def render_perp(mesh,fy,cam=np.eye(4),model=np.eye(4),resolution=[512,512]):\n",
    "    \n",
    "    obj = pyrender.Mesh.from_trimesh(mesh, smooth=True)\n",
    "    fovY = 2*np.arctan(resolution[0]/2/fy)\n",
    "    # compose scene\n",
    "    scene = pyrender.Scene(ambient_light=[0.1, 0.1, 0.1], bg_color=[0, 0, 0])\n",
    "    camera = pyrender.PerspectiveCamera( yfov=fovY)\n",
    "    light = pyrender.DirectionalLight(color=[1.0, 1.0, 1.0], intensity=8)\n",
    "\n",
    "    scene.add(obj, pose=  model)\n",
    "    scene.add(light, pose=  model)\n",
    "    scene.add(camera, pose = cam)\n",
    "    \n",
    "    # render scene\n",
    "    r = pyrender.OffscreenRenderer(resolution[1], resolution[0])\n",
    "    color, depth = r.render(scene)\n",
    "    return color,depth\n",
    "\n",
    "def render(mesh,fy,cam=np.eye(4),model=np.eye(4),resolution=[512,512]):\n",
    "\n",
    "    obj = pyrender.Mesh.from_trimesh(mesh, smooth=True)\n",
    "    fovY = 2*np.arctan(resolution[0]/2/fy)\n",
    "    # compose scene\n",
    "    scene = pyrender.Scene(ambient_light=[0.1, 0.1, 0.1], bg_color=[0, 0, 0])\n",
    "    camera = pyrender.PerspectiveCamera( yfov=fovY)\n",
    "    light = pyrender.DirectionalLight(color=[1.0, 1.0, 1.0], intensity=8)\n",
    "\n",
    "    scene.add(obj, pose=  model)\n",
    "    scene.add(light, pose=  model)\n",
    "    scene.add(camera, pose = cam)\n",
    "    \n",
    "    # render scene\n",
    "    r = pyrender.OffscreenRenderer(resolution[1], resolution[0])\n",
    "    color, depth = r.render(scene)\n",
    "    color,depth = color[::-1,::-1],depth[::-1,::-1]\n",
    "    return color,depth\n",
    "\n",
    "def _campos2matrix(cam_pos, cam_center=None, cam_up=None):\n",
    "    _cam_target = np.asarray([0,0.11,0.1]) if cam_center is None else cam_center\n",
    "    _cam_target = _cam_target.reshape((1, 3))\n",
    "    # print('*** cam_center = ', _cam_target.shape)\n",
    "\n",
    "    _cam_up = np.asarray([0.0, 1.0, 0.0]) if cam_up is None else cam_up\n",
    "\n",
    "    cam_dir = (_cam_target-cam_pos)\n",
    "    cam_dir = cam_dir / np.linalg.norm(cam_dir)\n",
    "    cam_right = np.cross(cam_dir, _cam_up)\n",
    "    cam_right = cam_right / np.linalg.norm(cam_right)\n",
    "    cam_up = np.cross(cam_right, cam_dir)\n",
    "\n",
    "    cam_R = np.concatenate([cam_right.T, -cam_up.T, cam_dir.T], axis=1)\n",
    "\n",
    "    cam_P = np.eye(4)\n",
    "    cam_P[:3, :3] = cam_R\n",
    "    cam_P[:3, 3] = cam_pos\n",
    "\n",
    "    return cam_P\n",
    "\n",
    "mesh = trimesh.load('../123.obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f,_IMG_SIZE = 500,128\n",
    "cam_K = np.array([[f,0,_IMG_SIZE//2],[0,f,_IMG_SIZE//2],[0,0,1]])\n",
    "\n",
    "lookat = np.asarray([0, 0.0, 0.0])\n",
    "cam_center =  np.asarray([0, 0.0, 1.0])\n",
    "cam_up = np.asarray([0.0, 1.0, 0.0])\n",
    "radii, focus_depth = np.asarray([0.1,0.12,0.1]), 4.5 # z,x,y\n",
    "\n",
    "\n",
    "# ROTATE\n",
    "R = np.linalg.norm(cam_center-lookat) + radii[0]\n",
    "\n",
    "theta = []\n",
    "_INTERP_STEPS = 20\n",
    "theta_range = [0.0, -0.55, 0.55, 0.0]\n",
    "for i in range(len(theta_range)-1):\n",
    "    theta.append( np.linspace(theta_range[i],theta_range[i+1], num=_INTERP_STEPS))\n",
    "theta = np.concatenate(theta)\n",
    "x = R*np.sin(theta)\n",
    "y = np.zeros_like(x)\n",
    "z = R*np.cos(theta)\n",
    "cam_T = np.stack([x,y,z],axis=1) + lookat.reshape((1,3))\n",
    "\n",
    "_IMG_SIZE = 128\n",
    "vis_outputs = []\n",
    "for i in range(len(theta)):\n",
    "    cam_P = _campos2matrix(cam_T[i], lookat)   \n",
    "    cam_P[:3, [1,2]] = -cam_P[:3,[1,2]]\n",
    "    \n",
    "    cam_P = np.linalg.inv(cam_P)\n",
    "    \n",
    "    color, depth = render_perp(mesh,f,model=cam_P,resolution=[_IMG_SIZE,_IMG_SIZE])\n",
    "    \n",
    "    vis_outputs.append(depth)\n",
    "    \n",
    "vis_fp ='../test.gif'\n",
    "imageio.mimsave(vis_fp, vis_outputs, fps=15.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
