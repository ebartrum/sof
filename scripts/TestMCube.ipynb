{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from modeling import SRNsModel\n",
    "from dataset.face_dataset import _campos2matrix\n",
    "\n",
    "import util\n",
    "from sklearn import mixture\n",
    "import meshplot as mp\n",
    "\n",
    "_RENDERER = 'FC'\n",
    "_ORTHO = False\n",
    "\n",
    "# _MODEL_PATH = '/home/anpei/liury/log/SRNs/072515face_seg_real/checkpoints/epoch_0045_iter_050000.pth'\n",
    "# _OPT_CAM = False\n",
    "# _ORTHO = True\n",
    "# _TOT_NUM_INSTANCES = 1689\n",
    "# focal = 30\n",
    "# cam_center =  np.asarray([0, 0, 2.0])\n",
    "# dpt_range = [0.0, 5.0]\n",
    "\n",
    "_MODEL_PATH = '../log/080320new_lstm/checkpoints//epoch_0184_iter_090000.pth'\n",
    "_OPT_CAM = False\n",
    "_ORTHO = False\n",
    "_TOT_NUM_INSTANCES = 122\n",
    "focal = 300\n",
    "cam_center =  np.asarray([0, 0, 1.0])\n",
    "dpt_range = [0.8, 1.2]\n",
    "\n",
    "_IMG_SIZE = 128\n",
    "_OUT_SIZE = 128\n",
    "\n",
    "_DEFAULT_CAM_INT = np.array([[focal,0,_IMG_SIZE//2],[0,focal,_IMG_SIZE//2],[0,0,1]])\n",
    "\n",
    "lookat = np.asarray([0, 0, 0])\n",
    "cam_up = np.asarray([0.0, 1.0, 0.0])\n",
    "_DEFAULT_CAM_POSE =  _campos2matrix(cam_center, lookat, cam_up)\n",
    "\n",
    "print('*** cams: ')\n",
    "print(_DEFAULT_CAM_INT)\n",
    "print(_DEFAULT_CAM_POSE)\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "model = SRNsModel(num_instances=_TOT_NUM_INSTANCES,\n",
    "                  latent_dim=256,\n",
    "                  renderer=_RENDERER,\n",
    "                  tracing_steps=10,\n",
    "                  freeze_networks=True,\n",
    "                  out_channels=20,\n",
    "                  img_sidelength=_IMG_SIZE,\n",
    "                  output_sidelength=_OUT_SIZE,\n",
    "                  opt_cam=_OPT_CAM,\n",
    "                  orthogonal=_ORTHO,\n",
    "                 )\n",
    "\n",
    "util.custom_load(model, path=_MODEL_PATH, discriminator=None,\n",
    "                 overwrite_embeddings=False, overwrite_cam=True)\n",
    "\n",
    "model.eval()\n",
    "model.cuda()\n",
    "\n",
    "_NUM_COMP = 1\n",
    "gmm = mixture.GaussianMixture(\n",
    "    n_components=_NUM_COMP, covariance_type='full', random_state=0)\n",
    "\n",
    "gmm.fit(model.latent_codes.weight.data.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from modeling import SRNsModel\n",
    "import util\n",
    "from sklearn import mixture\n",
    "\n",
    "_RENDERER = 'FC'\n",
    "_ORTHO = False\n",
    "\n",
    "_MODEL_PATH = '/home/anpei/liury/log/SRNs/092303face_seg_real_hidden3/checkpoints/epoch_0100_iter_020000.pth'\n",
    "# _MODEL_PATH = '../log/080320new_lstm/checkpoints//epoch_0184_iter_090000.pth'\n",
    "_OPT_CAM = False\n",
    "_ORTHO = True\n",
    "_TOT_NUM_INSTANCES = 221\n",
    "\n",
    "_IMG_SIZE = 128\n",
    "_OUT_SIZE = 128\n",
    "\n",
    "model = SRNsModel(num_instances=_TOT_NUM_INSTANCES,\n",
    "                  latent_dim=256,\n",
    "                  renderer=_RENDERER,\n",
    "                  tracing_steps=10,\n",
    "                  freeze_networks=True,\n",
    "                  out_channels=20,\n",
    "                  img_sidelength=_IMG_SIZE,\n",
    "                  output_sidelength=_OUT_SIZE,\n",
    "                  opt_cam=_OPT_CAM,\n",
    "                  orthogonal=_ORTHO,\n",
    "                 )\n",
    "\n",
    "util.custom_load(model, path=_MODEL_PATH, discriminator=None,\n",
    "                 overwrite_embeddings=False, overwrite_cam=True)\n",
    "\n",
    "model.eval()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from volRenderer import render_scene_cam, VolRender, _LABEL, _CMAP\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, IntSlider, FloatSlider\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def render_dpt(ins_id, dpt, vis_cls):\n",
    "    \n",
    "    latent = model.get_embedding({'instance_idx': torch.LongTensor([ins_id]).squeeze().cuda()}).unsqueeze(0)\n",
    "    \n",
    "    out_img, out_seg, prob, dpt_map = render_scene_cam(\n",
    "        model, latent, _DEFAULT_CAM_POSE, _DEFAULT_CAM_INT, _OUT_SIZE, dpt=dpt)\n",
    "    \n",
    "    figure=plt.figure(figsize=(10,5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(out_img)\n",
    "    plt.grid(\"off\");\n",
    "    plt.axis(\"off\");\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"depth\")\n",
    "    plt.imshow(dpt_map)\n",
    "    plt.grid(\"off\");\n",
    "    plt.axis(\"off\");\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(_LABEL[vis_cls])\n",
    "    plt.imshow(prob[:, :, vis_cls], cmap=plt.get_cmap('magma'))\n",
    "    plt.grid(\"off\");\n",
    "    plt.axis(\"off\");\n",
    "\n",
    "\n",
    "dpt_slider = FloatSlider(min=dpt_range[0], max=dpt_range[1], step=0.005)\n",
    "cls_slider = IntSlider(min=0, max=len(_LABEL)-1, step=1, value=0)\n",
    "ins_slider = IntSlider(min=0, max=_TOT_NUM_INSTANCES-1, step=1, value=136)\n",
    "    \n",
    "interactive_plot = interactive(render_dpt, ins_id=ins_slider, dpt=dpt_slider, vis_cls=cls_slider)\n",
    "output = interactive_plot.children[-1]\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = model.get_embedding({'instance_idx': torch.LongTensor([ins_slider.value]).squeeze().cuda()}).unsqueeze(0)\n",
    "_OUT_SIZE = 512\n",
    "renderer = VolRender(\n",
    "    model, z, _DEFAULT_CAM_POSE, _DEFAULT_CAM_INT, dpt_range, \n",
    "    ortho=_ORTHO, level_set=-0.5, resolution=(_OUT_SIZE, _OUT_SIZE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "from scipy.stats import norm\n",
    "\n",
    "remap_list = np.array([0,1,2,2,3,3,4,5,6,7,8,9,9,10,11,12,13,14,15,16]).astype('float')\n",
    "def id_remap(seg):\n",
    "    return remap_list[seg.astype('int')]\n",
    "\n",
    "def vis_condition_img(img):\n",
    "    part_colors = [[0, 0, 0], [127, 212, 255], [255, 255, 127], [255, 255, 170],#'skin',1 'eye_brow'2,  'eye'3\n",
    "                    [240, 157, 240], [255, 212, 255], #'r_nose'4, 'l_nose'5\n",
    "                    [31, 162, 230], [127, 255, 255], [127, 255, 255],#'mouth'6, 'u_lip'7,'l_lip'8\n",
    "                    [0, 255, 85], [0, 255, 170], #'ear'9 'ear_r'10\n",
    "                    [255, 255, 170],\n",
    "                    [127, 170, 255], [85, 0, 255], [255, 170, 127], #'neck'11, 'neck_l'12, 'cloth'13\n",
    "                    [212, 127, 255], [0, 170, 255],#, 'hair'14, 'hat'15\n",
    "                    [255, 255, 0], [255, 255, 85], [255, 255, 170],\n",
    "                    [255, 0, 255], [255, 85, 255], [255, 170, 255],\n",
    "                    [0, 255, 255], [85, 255, 255], [170, 255, 255], [100, 150, 200]]\n",
    "    H,W = img.shape\n",
    "    condition_img_color = np.zeros((H,W,3)).astype('uint8')\n",
    "\n",
    "    num_of_class = int(np.max(img))\n",
    "    for pi in range(1, num_of_class + 1):\n",
    "        index = np.where(img == pi)\n",
    "        condition_img_color[index[0], index[1],:] = part_colors[pi]\n",
    "    return condition_img_color\n",
    "\n",
    "def _campos2matrix(cam_pos, cam_center=None, cam_up=None):\n",
    "    _cam_target = np.asarray([0,0.11,0.1]) if cam_center is None else cam_center\n",
    "    _cam_target = _cam_target.reshape((1, 3))\n",
    "    # print('*** cam_center = ', _cam_target.shape)\n",
    "\n",
    "    _cam_up = np.asarray([0.0, 1.0, 0.0]) if cam_up is None else cam_up\n",
    "\n",
    "    cam_dir = (_cam_target-cam_pos)\n",
    "    cam_dir = cam_dir / np.linalg.norm(cam_dir)\n",
    "    cam_right = np.cross(cam_dir, _cam_up)\n",
    "    cam_right = cam_right / np.linalg.norm(cam_right)\n",
    "    cam_up = np.cross(cam_right, cam_dir)\n",
    "\n",
    "    cam_R = np.concatenate([cam_right.T, -cam_up.T, cam_dir.T], axis=1)\n",
    "\n",
    "    cam_P = np.eye(4)\n",
    "    cam_P[:3, :3] = cam_R\n",
    "    cam_P[:3, 3] = cam_pos\n",
    "\n",
    "    return cam_P\n",
    "\n",
    "def render_spiral_path(cam_center,lookat,radii,src_latent,trgt_latent, directions=None):\n",
    "    # ROTATE\n",
    "    R = np.linalg.norm(cam_center-lookat) + radii[0]\n",
    "\n",
    "    theta = []\n",
    "    theta_range = [0.0, -0.45, 0.45, 0.0]\n",
    "    for i in range(len(theta_range)-1):\n",
    "        theta.append( np.linspace(theta_range[i],theta_range[i+1], num=_INTERP_STEPS))\n",
    "#         theta.append(np.logspace(0.0, 1, 10, endpoint=False)[::-1]/100)\n",
    "    theta = np.concatenate(theta)\n",
    "    x = R*np.sin(theta)\n",
    "    y = np.zeros_like(x)\n",
    "    z = R*np.cos(theta)\n",
    "    cam_T = np.stack([x,y,z],axis=1) + lookat.reshape((1,3))\n",
    "\n",
    "    vis_outputs,out_segs = [],[]\n",
    "    for i in range(len(theta)):\n",
    "        cam_pose = _campos2matrix(cam_T[i], lookat)      \n",
    "        out_img, out_seg,_,_ = render_scene_cam(model, src_latent, cam_pose, _DEFAULT_CAM_INT, _OUT_SIZE)  \n",
    "\n",
    "        vis_outputs.append(out_img)\n",
    "        out_segs.append(out_seg)\n",
    "\n",
    "\n",
    "    # SPPIRAL PATH\n",
    "    t = np.linspace(0, 4*np.pi, _INTERP_STEPS*4, endpoint=True)\n",
    "    for k in range(len(t)):\n",
    "        cam_T = np.array([np.cos(t[k]), -np.sin(t[k]), -np.sin(0.5*t[k])]) * radii\n",
    "        cam_T = cam_T[[1,2,0]] + cam_center\n",
    "        cam_pose = _campos2matrix(cam_T, lookat)\n",
    "        out_img, out_seg,_,_ = render_scene_cam(model, src_latent, cam_pose, _DEFAULT_CAM_INT, _OUT_SIZE)  \n",
    "        vis_outputs.append(out_img)\n",
    "        out_segs.append(out_seg)\n",
    "\n",
    "    init_seg = out_seg.copy()\n",
    "    if directions is not None:\n",
    "        mouse_count = np.sum(init_seg==8)\n",
    "        init_seg[(init_seg>=2)*(init_seg<=10)] = 1\n",
    "        \n",
    "        direction = directions[0] if np.sum(mouse_count)<40 else directions[1]\n",
    "    \n",
    "        smile_latent = src_latent.clone()\n",
    "        steps = [0.3/_INTERP_STEPS]*_INTERP_STEPS*2\n",
    "        for j in steps:\n",
    "            smile_latent += j*direction\n",
    "            out_img, out_seg,_,_ = render_scene_cam(model, smile_latent, cam_pose, _DEFAULT_CAM_INT, _OUT_SIZE)  \n",
    "            mask = (out_seg>=2)*(out_seg<=10)\n",
    "            result = np.array(init_seg)\n",
    "            result[mask] = out_seg[mask]\n",
    "            out_segs.append(result)\n",
    "            vis_outputs.append(vis_condition_img(id_remap(result)))\n",
    "            \n",
    "    length = len(out_segs)\n",
    "    for i in range(_INTERP_STEPS*2):\n",
    "        out_segs.append(out_segs[length-i-1])\n",
    "        vis_outputs.append(vis_outputs[length-i-1])\n",
    "        \n",
    "    cdf_scale = 1.0/(1.0-norm.cdf(-_INTERP_STEPS,0,6)*2)\n",
    "    for idx in range(-_INTERP_STEPS,_INTERP_STEPS+1):\n",
    "        \n",
    "        _w = (norm.cdf(idx,0,6)-norm.cdf(-_INTERP_STEPS,0,6))*cdf_scale\n",
    "        latent = (1.0-_w)*src_latent + _w*trgt_latent\n",
    "        \n",
    "        out_img, out_seg,_,_ = render_scene_cam(model, latent, cam_pose, _DEFAULT_CAM_INT, _OUT_SIZE) \n",
    "        vis_outputs.append(out_img)\n",
    "        out_segs.append(out_seg)\n",
    "\n",
    "\n",
    "#     for k in range(len(t)):\n",
    "#         cam_T = np.array([np.cos(t[k]), -np.sin(t[k]), -np.sin(0.5*t[k])]) * radii\n",
    "#         cam_T = cam_T[[1,2,0]] + cam_center\n",
    "#         cam_pose = _campos2matrix(cam_T, lookat)\n",
    "#         out_img, out_seg,_,_ = render_scene_cam(model, latent, cam_pose, _DEFAULT_CAM_INT, _OUT_SIZE)  \n",
    "#         vis_outputs.append(out_img)\n",
    "#         out_segs.append(out_seg)\n",
    "\n",
    "#     for idx in range(-_INTERP_STEPS,_INTERP_STEPS+1):\n",
    "#         _w = (norm.cdf(idx,0,6)-norm.cdf(-_INTERP_STEPS,0,6))*cdf_scale\n",
    "#         latent = (1.0-_w)*trgt_latent + _w*src_latent\n",
    "#         out_img, out_seg,_,_ = render_scene_cam(model, latent, cam_pose, _DEFAULT_CAM_INT, _OUT_SIZE)\n",
    "#         vis_outputs.append(out_img)\n",
    "#         out_segs.append(out_seg)\n",
    "\n",
    "    length = len(out_segs)\n",
    "    for i in range(_INTERP_STEPS*2):\n",
    "        out_segs.append(out_segs[length-i-1])\n",
    "        vis_outputs.append(vis_outputs[length-i-1])\n",
    "        \n",
    "\n",
    "    return out_segs,vis_outputs\n",
    "\n",
    "def render_spiral_path_withDepth(render, src_latent, trgt_latent=None, dst_latent=None, directions=None):\n",
    "    # ROTATE\n",
    "    R = np.linalg.norm(cam_center-lookat) + radii[0]\n",
    "\n",
    "    theta = []\n",
    "    theta_range = [0.0, -0.55, 0.55, 0.0]\n",
    "    for i in range(len(theta_range)-1):\n",
    "        theta.append( np.linspace(theta_range[i],theta_range[i+1], num=_INTERP_STEPS))\n",
    "\n",
    "    theta = np.concatenate(theta)\n",
    "    x = R*np.sin(theta)\n",
    "    y = np.zeros_like(x)\n",
    "    z = R*np.cos(theta)\n",
    "    cam_T = np.stack([x,y,z],axis=1) + lookat.reshape((1,3))\n",
    "\n",
    "    vis_outputs,out_segs = [],[]\n",
    "    for i in range(len(theta)):\n",
    "        cam_pose = _campos2matrix(cam_T[i], lookat)        \n",
    "        _, out_img_with_init, _, out_seg_with_init, _, _, _ = renderer.render(cam_pose, _DEFAULT_CAM_INT, resolution=[_IMG_SIZE, _IMG_SIZE])\n",
    "\n",
    "        vis_outputs.append(out_img_with_init)\n",
    "        out_segs.append(out_seg_with_init)\n",
    "\n",
    "\n",
    "    # SPPIRAL PATH\n",
    "    t = np.linspace(0, 4*np.pi, _INTERP_STEPS*4, endpoint=True)\n",
    "    for k in range(len(t)):\n",
    "        cam_T = np.array([np.cos(t[k]), -np.sin(t[k]), -np.sin(0.5*t[k])]) * radii\n",
    "        cam_T = cam_T[[1,2,0]] + cam_center\n",
    "        cam_pose = _campos2matrix(cam_T, lookat)\n",
    "        _, out_img_with_init, _, out_seg_with_init, _, _, _ = renderer.render(cam_pose, _DEFAULT_CAM_INT, resolution=[_IMG_SIZE, _IMG_SIZE])\n",
    "\n",
    "        vis_outputs.append(out_img_with_init)\n",
    "        out_segs.append(out_seg_with_init)\n",
    "\n",
    "    init_seg = out_seg_with_init.copy()\n",
    "    if directions is not None:\n",
    "        mouse_count = np.sum(init_seg==8)\n",
    "        out_seg_with_init[(init_seg>=2)*(init_seg<=10)] = 1\n",
    "        \n",
    "        direction = directions[0] if np.sum(mouse_count)<40 else directions[1]\n",
    "    \n",
    "        smile_latent = src_latent.clone()\n",
    "        steps = [0.3/_INTERP_STEPS]*_INTERP_STEPS*2 \n",
    "        for j in steps:\n",
    "            smile_latent += j*direction\n",
    "            render = VolRender(model, smile_latent, _DEFAULT_CAM_POSE, _DEFAULT_CAM_INT, dpt_range, \n",
    "                ortho=_ORTHO, level_set=-0.5, resolution=(_OUT_SIZE, _OUT_SIZE))\n",
    "            \n",
    "            _, out_img_with_init, _, out_seg_with_init, _, _, _ = renderer.render(cam_pose, _DEFAULT_CAM_INT, resolution=[_IMG_SIZE, _IMG_SIZE])\n",
    "            mask = (out_seg_with_init>=2)*(out_seg_with_init<=10)\n",
    "            result = np.array(init_seg)\n",
    "            result[mask] = out_seg_with_init[mask]\n",
    "            out_segs.append(result)\n",
    "            \n",
    "            vis_outputs.append(vis_condition_img(id_remap(result)))\n",
    "    \n",
    "    length = len(out_segs)\n",
    "    for i in range(_INTERP_STEPS*2):\n",
    "        out_segs.append(out_segs[length-i-1])\n",
    "        vis_outputs.append(vis_outputs[length-i-1])\n",
    "        \n",
    "    cdf_scale = 1.0/(1.0-norm.cdf(-_INTERP_STEPS,0,6)*2)\n",
    "    for idx in range(-_INTERP_STEPS,_INTERP_STEPS+1):\n",
    "        \n",
    "        _w = (norm.cdf(idx,0,6)-norm.cdf(-_INTERP_STEPS,0,6))*cdf_scale\n",
    "        latent = (1.0-_w)*src_latent + _w*trgt_latent\n",
    "        \n",
    "        render = VolRender(model, latent, _DEFAULT_CAM_POSE, _DEFAULT_CAM_INT, dpt_range, \n",
    "                ortho=_ORTHO, level_set=-0.5, resolution=(_OUT_SIZE, _OUT_SIZE))\n",
    "            \n",
    "        _, out_img_with_init, _, out_seg_with_init, _, _, _ = renderer.render(cam_pose, _DEFAULT_CAM_INT, resolution=[_IMG_SIZE, _IMG_SIZE])\n",
    "        vis_outputs.append(out_img_with_init)\n",
    "        out_segs.append(out_seg_with_init)\n",
    "\n",
    "\n",
    "#     for k in range(len(t)):\n",
    "#         cam_T = np.array([np.cos(t[k]), -np.sin(t[k]), -np.sin(0.5*t[k])]) * radii\n",
    "#         cam_T = cam_T[[1,2,0]] + cam_center\n",
    "#         cam_pose = _campos2matrix(cam_T, lookat)\n",
    "#         out_img, out_seg = render_scene_cam(model, cam_pose, trgt_latent, _DEFAULT_CAM_INT, _OUT_SIZE, orthogonal=_ORTHO)  \n",
    "#         vis_outputs.append(out_img)\n",
    "#         out_segs.append(out_seg)\n",
    "\n",
    "#     for idx in range(-_INTERP_STEPS//2,_INTERP_STEPS//2+1):\n",
    "#         _w = (norm.cdf(idx,0,6)-norm.cdf(-_INTERP_STEPS//2,0,6))*cdf_scale\n",
    "#         latent = (1.0-_w)*trgt_latent + _w*src_latent\n",
    "#         out_img, out_seg = render_scene_cam(model, cam_pose, latent, _DEFAULT_CAM_INT, _OUT_SIZE, orthogonal=_ORTHO) \n",
    "#         vis_outputs.append(out_img)\n",
    "#         out_segs.append(out_seg)\n",
    "\n",
    "\n",
    "    length = len(out_segs)\n",
    "    for i in range(_INTERP_STEPS*2):\n",
    "        out_segs.append(out_segs[length-i-1])\n",
    "        vis_outputs.append(vis_outputs[length-i-1])\n",
    "        \n",
    "    return out_segs,vis_outputs\n",
    "\n",
    "_OUT_SIZE = 128\n",
    "_IMG_SIZE = 128\n",
    "f = 480*(_IMG_SIZE/128)\n",
    "_DEFAULT_CAM_INT = np.array([[f,0,_IMG_SIZE//2],[0,f,_IMG_SIZE//2],[0,0,1]])\n",
    "\n",
    "lookat = np.asarray([0, 0.0, 0.0])\n",
    "cam_center =  np.asarray([0, 0.0, 1.0])\n",
    "cam_up = np.asarray([0.0, 1.0, 0.0])\n",
    "radii, focus_depth = np.asarray([0.1,0.12,0.1]), 4.5 # z,x,y\n",
    "\n",
    "\n",
    "\n",
    "num_comp = 16\n",
    "gmm = mixture.GaussianMixture(\n",
    "    n_components=num_comp, covariance_type='full')\n",
    "gmm.fit(model.latent_codes.weight.data.cpu().numpy())\n",
    "\n",
    "_LOG_ROOT = '/mnt/data/new_disk/chenap/dataset/mv'\n",
    "smile_dir = torch.from_numpy(np.load('/home/anpei/Jack12/MicrosoftAzure/happiness_dir.npy')).float()\n",
    "neutral_dir = torch.from_numpy(np.load('/home/anpei/Jack12/MicrosoftAzure/neutral_dir.npy')).float()\n",
    "directions = torch.stack((smile_dir,neutral_dir),dim=0)\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    print(i)\n",
    "    src_latent = torch.from_numpy(gmm.sample(1)[0]).float()\n",
    "    dst_latent = torch.from_numpy(gmm.sample(1)[0]).float()\n",
    "    \n",
    "#     z = model.get_embedding({'instance_idx': torch.LongTensor([ins_slider.value]).squeeze().cuda()}).unsqueeze(0)\n",
    "\n",
    "#     render = VolRender(\n",
    "#         model, src_latent, _DEFAULT_CAM_POSE, _DEFAULT_CAM_INT, dpt_range, \n",
    "#         ortho=_ORTHO, level_set=-0.5, resolution=(_OUT_SIZE, _OUT_SIZE))\n",
    "\n",
    "#     out_segs,vis_outputs = render_spiral_path_withDepth(render, src_latent, dst_latent, directions=directions)\n",
    "\n",
    "    out_segs,vis_outputs = render_spiral_path(cam_center,lookat,radii,src_latent,dst_latent, directions=directions)\n",
    "    \n",
    "    # save data\n",
    "    os.makedirs(os.path.join(_LOG_ROOT, '%03d'%i),exist_ok=True)\n",
    "    os.makedirs(os.path.join(_LOG_ROOT, 'vis'),exist_ok=True)\n",
    "    for k,out_seg in enumerate(out_segs):\n",
    "        output_fp = os.path.join(_LOG_ROOT, '%03d'%i,'%03d.png'%k)\n",
    "        util.write_img(out_seg, output_fp)\n",
    "    \n",
    "    vis_fp = output_fp = os.path.join(_LOG_ROOT, 'vis','%03d.gif'%i)\n",
    "    imageio.mimsave(vis_fp, vis_outputs, fps=15.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.from_numpy(np.load('/home/anpei/Jack12/MicrosoftAzure/happiness_dir.npy')).float().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = model.get_embedding({'instance_idx': torch.LongTensor([91]).squeeze().cuda()}).unsqueeze(0)\n",
    "_OUT_SIZE = 256\n",
    "dpt_range = [0.83,1.15]\n",
    "_DEFAULT_CAM_INT = np.array([[400*_OUT_SIZE/128,0,_OUT_SIZE//2],[0,400*_OUT_SIZE/128,_OUT_SIZE//2],[0,0,1]])\n",
    "renderer = VolRender(\n",
    "    model, z, _DEFAULT_CAM_POSE, _DEFAULT_CAM_INT, dpt_range, \n",
    "    ortho=_ORTHO, level_set=-0.5, resolution=(_OUT_SIZE, _OUT_SIZE))\n",
    "p = mp.plot(renderer.world_v, renderer.f, 1.0-renderer.color,return_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_steps = np.linspace(1.1,3.0, num=8)\n",
    "for i,d in enumerate(depth_steps):\n",
    "    cam_center =  np.asarray([0, 0.0, d])\n",
    "    _DEFAULT_CAM_INT = np.array([[400*_OUT_SIZE/128+200*i,0,_OUT_SIZE//2],[0,400*_OUT_SIZE/128+200*i,_OUT_SIZE//2],[0,0,1]])\n",
    "    cam_P = _campos2matrix(cam_center, lookat)   \n",
    "\n",
    "    out_seg, out_seg_with_init, pred_dpt, pred_dpt_with_init, depth_piror = renderer.render(cam_P, _DEFAULT_CAM_INT, resolution=[_OUT_SIZE, _OUT_SIZE])\n",
    "    depth_piror[depth_piror==0] = 10\n",
    "    \n",
    "    depth = np.concatenate((pred_dpt, pred_dpt_with_init, depth_piror),axis=1)\n",
    "    depth_min, depth_max = np.min(depth[depth>0]), np.max(depth[depth>0])\n",
    "    depth = (depth-cam_center[2]+0.25)/0.3\n",
    "    depth_image = np.round(depth*255).astype('uint8')\n",
    "    depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=1.0), cv2.COLORMAP_JET)\n",
    "    \n",
    "    result = np.concatenate((out_seg,out_seg_with_init,depth_colormap),axis=1)\n",
    "    cv2.imwrite('/home/anpei/Desktop/softgan_test/result/our_marching_cube_%03d.png'%i,result[...,::-1])\n",
    "#     plt.imshow(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 1.1\n",
    "theta = []\n",
    "theta_range = [-1.0, 1.0]\n",
    "for i in range(len(theta_range)-1):\n",
    "    theta.append( np.linspace(theta_range[i],theta_range[i+1], num=5, endpoint=True))\n",
    "theta = np.concatenate(theta)\n",
    "x = R*np.sin(theta)\n",
    "y = np.zeros_like(x)\n",
    "z = R*np.cos(theta)\n",
    "cam_T = np.stack([x,y,z],axis=1) + lookat.reshape((1,3))\n",
    "_DEFAULT_CAM_INT = np.array([[450*_OUT_SIZE/128,0,_OUT_SIZE//2],[0,450*_OUT_SIZE/128,_OUT_SIZE//2],[0,0,1]])\n",
    "\n",
    "vis_outputs = []\n",
    "for i in range(len(theta)):\n",
    "    cam_P = _campos2matrix(cam_T[i], lookat)   \n",
    "    out_seg, out_seg_with_init, pred_dpt, pred_dpt_with_init, depth_piror = renderer.render(cam_P, _DEFAULT_CAM_INT, resolution=[_OUT_SIZE, _OUT_SIZE])\n",
    "\n",
    "    cv2.imwrite('/home/anpei/Desktop/softgan_test/result/our_segmap_%03d.png'%i,out_seg[...,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_P = _campos2matrix(cam_T[0], lookat)   \n",
    "render_cam_P = np.array(cam_P)\n",
    "render_cam_P[:,2] = -render_cam_P[:,2]\n",
    "render_cam_P = np.linalg.inv(render_cam_P)\n",
    "render_cam_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh,pyrender\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def renderDepth_ortho(mesh,cam=np.eye(4),model=np.eye(4),scale=[1,1],resolution=[720,1280]):\n",
    "\n",
    "    obj = pyrender.Mesh.from_trimesh(mesh, smooth=False)\n",
    "\n",
    "    scene = pyrender.Scene(ambient_light=[1.0, 1.0, 1.0], bg_color=[0, 0, 0])\n",
    "    camera = pyrender.OrthographicCamera(xmag=1, ymag=resolution[1]/2/scale[1], znear=1e-3, zfar=10000.0)\n",
    "    light = pyrender.DirectionalLight(color=[1.0, 1.0, 1.0], intensity=2.0)\n",
    "\n",
    "    scene.add(obj, pose=  model)\n",
    "    scene.add(light, pose=  model)\n",
    "    scene.add(camera, pose = cam)\n",
    "    \n",
    "    # render scene\n",
    "    r = pyrender.OffscreenRenderer(resolution[1], resolution[0])\n",
    "    color, depth = r.render(scene)\n",
    "    \n",
    "    return color, depth\n",
    "\n",
    "def render_perp(mesh,fy,cam=np.eye(4),model=np.eye(4),resolution=[512,512]):\n",
    "    \n",
    "    obj = pyrender.Mesh.from_trimesh(mesh, smooth=True)\n",
    "    fovY = 2*np.arctan(resolution[0]/2/fy)\n",
    "    # compose scene\n",
    "    scene = pyrender.Scene(ambient_light=[0.1, 0.1, 0.1], bg_color=[0, 0, 0])\n",
    "    camera = pyrender.PerspectiveCamera( yfov=fovY)\n",
    "    light = pyrender.DirectionalLight(color=[1.0, 1.0, 1.0], intensity=8)\n",
    "\n",
    "    scene.add(obj, pose=  model)\n",
    "    scene.add(light, pose=  model)\n",
    "    scene.add(camera, pose = cam)\n",
    "    \n",
    "    # render scene\n",
    "    r = pyrender.OffscreenRenderer(resolution[1], resolution[0])\n",
    "    color, depth = r.render(scene)\n",
    "    return color,depth\n",
    "\n",
    "def render(mesh,fy,cam=np.eye(4),model=np.eye(4),resolution=[512,512]):\n",
    "\n",
    "    obj = pyrender.Mesh.from_trimesh(mesh, smooth=True)\n",
    "    fovY = 2*np.arctan(resolution[0]/2/fy)\n",
    "    # compose scene\n",
    "    scene = pyrender.Scene(ambient_light=[0.1, 0.1, 0.1], bg_color=[0, 0, 0])\n",
    "    camera = pyrender.PerspectiveCamera( yfov=fovY)\n",
    "    light = pyrender.DirectionalLight(color=[1.0, 1.0, 1.0], intensity=8)\n",
    "\n",
    "    scene.add(obj, pose=  model)\n",
    "    scene.add(light, pose=  model)\n",
    "    scene.add(camera, pose = cam)\n",
    "    \n",
    "    # render scene\n",
    "    r = pyrender.OffscreenRenderer(resolution[1], resolution[0])\n",
    "    color, depth = r.render(scene)\n",
    "    color,depth = color[::-1,::-1],depth[::-1,::-1]\n",
    "    return color,depth\n",
    "\n",
    "def _campos2matrix(cam_pos, cam_center=None, cam_up=None):\n",
    "    _cam_target = np.asarray([0,0.11,0.1]) if cam_center is None else cam_center\n",
    "    _cam_target = _cam_target.reshape((1, 3))\n",
    "    # print('*** cam_center = ', _cam_target.shape)\n",
    "\n",
    "    _cam_up = np.asarray([0.0, 1.0, 0.0]) if cam_up is None else cam_up\n",
    "\n",
    "    cam_dir = (_cam_target-cam_pos)\n",
    "    cam_dir = cam_dir / np.linalg.norm(cam_dir)\n",
    "    cam_right = np.cross(cam_dir, _cam_up)\n",
    "    cam_right = cam_right / np.linalg.norm(cam_right)\n",
    "    cam_up = np.cross(cam_right, cam_dir)\n",
    "\n",
    "    cam_R = np.concatenate([cam_right.T, -cam_up.T, cam_dir.T], axis=1)\n",
    "\n",
    "    cam_P = np.eye(4)\n",
    "    cam_P[:3, :3] = cam_R\n",
    "    cam_P[:3, 3] = cam_pos\n",
    "\n",
    "    return cam_P\n",
    "\n",
    "mesh = trimesh.load('../123.obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f,_IMG_SIZE = 500,128\n",
    "cam_K = np.array([[f,0,_IMG_SIZE//2],[0,f,_IMG_SIZE//2],[0,0,1]])\n",
    "\n",
    "lookat = np.asarray([0, 0.0, 0.0])\n",
    "cam_center =  np.asarray([0, 0.0, 1.0])\n",
    "cam_up = np.asarray([0.0, 1.0, 0.0])\n",
    "radii, focus_depth = np.asarray([0.1,0.12,0.1]), 4.5 # z,x,y\n",
    "\n",
    "\n",
    "# ROTATE\n",
    "R = np.linalg.norm(cam_center-lookat) + radii[0]\n",
    "\n",
    "theta = []\n",
    "_INTERP_STEPS = 20\n",
    "theta_range = [0.0, -0.55, 0.55, 0.0]\n",
    "for i in range(len(theta_range)-1):\n",
    "    theta.append( np.linspace(theta_range[i],theta_range[i+1], num=_INTERP_STEPS))\n",
    "theta = np.concatenate(theta)\n",
    "x = R*np.sin(theta)\n",
    "y = np.zeros_like(x)\n",
    "z = R*np.cos(theta)\n",
    "cam_T = np.stack([x,y,z],axis=1) + lookat.reshape((1,3))\n",
    "\n",
    "_IMG_SIZE = 128\n",
    "vis_outputs = []\n",
    "for i in range(len(theta)):\n",
    "    cam_P = _campos2matrix(cam_T[i], lookat)   \n",
    "    cam_P[:3, [1,2]] = -cam_P[:3,[1,2]]\n",
    "    \n",
    "    cam_P = np.linalg.inv(cam_P)\n",
    "    \n",
    "    color, depth = render_perp(mesh,f,model=cam_P,resolution=[_IMG_SIZE,_IMG_SIZE])\n",
    "    \n",
    "    vis_outputs.append(depth)\n",
    "    \n",
    "vis_fp ='../test.gif'\n",
    "imageio.mimsave(vis_fp, vis_outputs, fps=15.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
