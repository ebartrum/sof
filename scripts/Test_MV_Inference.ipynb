{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# seg face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INIT embedding] variable.\n",
      "[INIT renderer] FC, with renderer = FC\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SRNsModel(\n",
       "  (latent_codes): Embedding(122, 256)\n",
       "  (hyper_phi): HyperFC(\n",
       "    (layers): ModuleList(\n",
       "      (0): NewCls(\n",
       "        (hyper_linear): HyperLinear(\n",
       "          (hypo_params): FCBlock(\n",
       "            (net): Sequential(\n",
       "              (0): FCLayer(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                  (2): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): FCLayer(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                  (2): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (norm_nl): Sequential(\n",
       "          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): NewCls(\n",
       "        (hyper_linear): HyperLinear(\n",
       "          (hypo_params): FCBlock(\n",
       "            (net): Sequential(\n",
       "              (0): FCLayer(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                  (2): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): FCLayer(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                  (2): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Linear(in_features=256, out_features=65792, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (norm_nl): Sequential(\n",
       "          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): NewCls(\n",
       "        (hyper_linear): HyperLinear(\n",
       "          (hypo_params): FCBlock(\n",
       "            (net): Sequential(\n",
       "              (0): FCLayer(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                  (2): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): FCLayer(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                  (2): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Linear(in_features=256, out_features=65792, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (norm_nl): Sequential(\n",
       "          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ray_marcher): Raymarcher(\n",
       "    (lstm): Linear(\n",
       "      (linear): ModuleList(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (1): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (2): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (3): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (4): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (5): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (6): Linear(in_features=256, out_features=1, bias=False)\n",
       "      )\n",
       "      (bias): ModuleList(\n",
       "        (0): Linear(in_features=3, out_features=256, bias=True)\n",
       "        (1): Linear(in_features=3, out_features=256, bias=True)\n",
       "        (2): Linear(in_features=3, out_features=256, bias=True)\n",
       "        (3): Linear(in_features=3, out_features=256, bias=True)\n",
       "        (4): Linear(in_features=3, out_features=256, bias=True)\n",
       "        (5): Linear(in_features=3, out_features=256, bias=True)\n",
       "        (6): Linear(in_features=3, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pixel_generator): FCBlock(\n",
       "    (net): Sequential(\n",
       "      (0): FCLayer(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): FCLayer(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): FCLayer(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): Linear(in_features=256, out_features=20, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (l2_loss): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys,os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from modeling import SRNsModel\n",
    "import util\n",
    "from sklearn import mixture\n",
    "\n",
    "_RENDERER = 'FC'\n",
    "_ORTHO = False\n",
    "\n",
    "# _MODEL_PATH = '../checkpoints/epoch_0020_iter_090000.pth'\n",
    "# _TOT_NUM_INSTANCES = 1494\n",
    "# _OPT_CAM = False\n",
    "\n",
    "# _MODEL_PATH = '../checkpoints/050701face_seg_2000_depth.pth'\n",
    "# _OPT_CAM = False\n",
    "# _TOT_NUM_INSTANCES = 3714\n",
    "\n",
    "# _MODEL_PATH = '/root/liury/log/SRNs/060706face_celebA/checkpoints/epoch_1359_iter_170000.pth'\n",
    "# _OPT_CAM = True\n",
    "# _TOT_NUM_INSTANCES = 1000\n",
    "\n",
    "\n",
    "# _MODEL_PATH = '/root/liury/log/SRNs/061905seg_teaser/checkpoints/epoch_2400_iter_012000.pth'\n",
    "# _OPT_CAM = True\n",
    "# _TOT_NUM_INSTANCES = 37\n",
    "\n",
    "\n",
    "# _MODEL_PATH = '../checkpoints/061721face_seg_800.pth'\n",
    "# _OPT_CAM = False\n",
    "# _TOT_NUM_INSTANCES = 791\n",
    "\n",
    "# _MODEL_PATH = '/home/anpei/liury/log/SRNs/062923face_seg_800/checkpoints/epoch_0036_iter_110000.pth'\n",
    "# _OPT_CAM = False\n",
    "# _TOT_NUM_INSTANCES = 711\n",
    "\n",
    "# _MODEL_PATH = '/home/anpei/liury/log/SRNs/070212face_seg_800/checkpoints/epoch_0010_iter_030000.pth'\n",
    "# _OPT_CAM = False\n",
    "# _TOT_NUM_INSTANCES = 664\n",
    "\n",
    "\n",
    "# _MODEL_PATH = '/home/anpei/liury/log/SRNs/070821face_seg_800_imae/checkpoints/epoch_0007_iter_020000.pth'\n",
    "# _OPT_CAM = False\n",
    "# _TOT_NUM_INSTANCES = 664\n",
    "# _RENDERER = 'ImAE'\n",
    "\n",
    "# _MODEL_PATH = '/home/anpei/liury/log/SRNs/061701face_celebA/checkpoints/epoch_0840_iter_420000.pth'\n",
    "# _OPT_CAM = True\n",
    "# _TOT_NUM_INSTANCES = 4000\n",
    "\n",
    "# _MODEL_PATH = os.path.join(\n",
    "#     os.getenv(\"HOME\"), 'liury/log/SRNs/061916face_celebA/checkpoints/epoch_2000_iter_014000.pth')\n",
    "# _LOG_ROOT = os.path.join(\n",
    "#     os.getenv(\"HOME\"), 'liury/log/SRNs/061916face_celebA/reproj_celebA')\n",
    "# os.makedirs(os.path.join(_LOG_ROOT, 'vis'), exist_ok=True)\n",
    "# _OPT_CAM=True\n",
    "\n",
    "# _TOT_NUM_INSTANCES = 50\n",
    "# _TOT_NUM_INSTANCES = 3714\n",
    "\n",
    "# # _MODEL_PATH = '/home/anpei/liury/log/SRNs/072515face_seg_real/checkpoints/epoch_0045_iter_050000.pth'\n",
    "\n",
    "# _MODEL_PATH = '/home/anpei/liury/log/SRNs/092303face_seg_real_hidden3/checkpoints/epoch_0100_iter_020000.pth'\n",
    "_MODEL_PATH = '../log/080320new_lstm/checkpoints//epoch_0184_iter_090000.pth'\n",
    "_OPT_CAM = False\n",
    "_ORTHO = True\n",
    "_TOT_NUM_INSTANCES = 122\n",
    "\n",
    "_IMG_SIZE = 128\n",
    "_OUT_SIZE = 128\n",
    "\n",
    "\n",
    "# CelebA 0809\n",
    "# _MODEL_PATH = '/mnt/data/new_disk2/liury/log/SRNs/080903face_celebA_10k/checkpoints/epoch_0043_iter_109000.pth'\n",
    "# _OPT_CAM = True\n",
    "# _ORTHO = True\n",
    "# _TOT_NUM_INSTANCES = 10000\n",
    "\n",
    "# _IMG_SIZE = 128\n",
    "# _OUT_SIZE = 128\n",
    "\n",
    "\n",
    "\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "# torch.cuda.set_device(0)\n",
    "\n",
    "model = SRNsModel(num_instances=_TOT_NUM_INSTANCES,\n",
    "                  latent_dim=256,\n",
    "                  renderer=_RENDERER,\n",
    "                  tracing_steps=10,\n",
    "                  freeze_networks=True,\n",
    "                  out_channels=20,\n",
    "                  img_sidelength=_IMG_SIZE,\n",
    "                  output_sidelength=_OUT_SIZE,\n",
    "                  opt_cam=_OPT_CAM,\n",
    "                  orthogonal=_ORTHO,\n",
    "                 )\n",
    "\n",
    "util.custom_load(model, path=_MODEL_PATH, discriminator=None,\n",
    "                 overwrite_embeddings=False, overwrite_cam=True)\n",
    "\n",
    "model.eval()\n",
    "model.cuda()\n",
    "\n",
    "# _NUM_COMP = 1\n",
    "# gmm = mixture.GaussianMixture(\n",
    "#     n_components=_NUM_COMP, covariance_type='full', random_state=0)\n",
    "\n",
    "# gmm.fit(model.latent_codes.weight.data.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dataset.face_dataset import _campos2matrix\n",
    "import cv2\n",
    "from skimage import morphology\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "_CMAP = np.asarray([[0, 0, 0], [127, 212, 255], [255, 255, 127], [255, 255, 127], # 'background','skin', 'l_brow', 'r_brow'\n",
    "                    [255, 255, 170], [255, 255, 170], [240, 157, 240], [255, 212, 255], #'l_eye', 'r_eye', 'r_nose', 'l_nose',\n",
    "                    [31, 162, 230], [127, 255, 255], [127, 255, 255], #'mouth', 'u_lip', 'l_lip'\n",
    "                    [0, 255, 85], [0, 255, 85], [0, 255, 170], [255, 255, 170], #'l_ear', 'r_ear', 'ear_r', 'eye_g'\n",
    "                    [127, 170, 255], [85, 0, 255], [255, 170, 127], #'neck', 'neck_l', 'cloth'\n",
    "                    [212, 127, 255], [0, 170, 255]#, 'hair', 'hat'\n",
    "                    ])\n",
    "\n",
    "_CMAP =torch.tensor(_CMAP, dtype=torch.float32) / 255.0\n",
    "\n",
    "def _build_cam_int(focal, H, W):\n",
    "    return np.array([  [focal, 0., W // 2, 0.],\n",
    "                       [0., focal, H // 2, 0],\n",
    "                       [0., 0, 1, 0],\n",
    "                       [0, 0, 0, 1]])\n",
    "\n",
    "\n",
    "def render_scene(model, pose, z, focal, img_sidelength):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pose = torch.from_numpy(pose).float().unsqueeze(0)\n",
    "        cam_int = torch.from_numpy(\n",
    "            _build_cam_int(focal, _IMG_SIZE, _IMG_SIZE)).float().unsqueeze(0)\n",
    "\n",
    "        uv = np.mgrid[0:_IMG_SIZE, 0:_IMG_SIZE].astype(np.int32)\n",
    "        uv = torch.from_numpy(np.flip(uv, axis=0).copy()).long()\n",
    "        uv = uv.reshape(2, -1).transpose(1, 0).unsqueeze(0)\n",
    "\n",
    "#         print(pose.shape, cam_int.shape, uv.shape, z.shape)\n",
    "\n",
    "        predictions, depth_maps = model(pose, z, cam_int, uv)\n",
    "\n",
    "        pred = torch.argmax(predictions, dim=2, keepdim=True)\n",
    "\n",
    "#         print(pred.shape)\n",
    "\n",
    "        out_img = util.lin2img(pred, color_map=_CMAP).cpu().numpy()\n",
    "        out_seg = pred.view(img_sidelength, img_sidelength, 1).cpu().numpy()\n",
    "        \n",
    "        out_img = (out_img.squeeze().transpose(1, 2, 0)) * 255.0\n",
    "        out_img = out_img.round().clip(0, 255).astype(np.uint8)\n",
    "\n",
    "        out_seg = out_seg.squeeze().astype(np.uint8)\n",
    "        out_seg = morphology.area_closing(out_seg, area_threshold=6000)\n",
    "\n",
    "\n",
    "        return out_img, out_seg\n",
    "    \n",
    "    \n",
    "def render_scene_cam(model, pose, z, cam_int, img_sidelength,orthogonal=True):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pose = torch.from_numpy(pose).float().unsqueeze(0)\n",
    "        cam_int = torch.from_numpy(cam_int).float().unsqueeze(0)\n",
    "        \n",
    "#         print('*** cam_int = ', cam_int)\n",
    "\n",
    "        uv = np.mgrid[0:_IMG_SIZE, 0:_IMG_SIZE].astype(np.int32)\n",
    "        uv = torch.from_numpy(np.flip(uv, axis=0).copy()).long()\n",
    "        uv = uv.reshape(2, -1).transpose(1, 0).unsqueeze(0)\n",
    "\n",
    "#         print(pose.shape, cam_int.shape, uv.shape, z.shape)\n",
    "\n",
    "        predictions, depth_maps = model(pose, z, cam_int, uv, orthogonal=orthogonal)\n",
    "\n",
    "        pred = torch.argmax(predictions, dim=2, keepdim=True)\n",
    "\n",
    "#         print(pred.shape)\n",
    "\n",
    "        out_img = util.lin2img(pred, color_map=_CMAP).cpu().numpy()\n",
    "        out_seg = pred.view(img_sidelength, img_sidelength, 1).cpu().numpy()\n",
    "        \n",
    "        out_img = (out_img.squeeze().transpose(1, 2, 0)) * 255.0\n",
    "        out_img = out_img.round().clip(0, 255).astype(np.uint8)\n",
    "\n",
    "#         output_fp = os.path.join(instance_dir, '%02d_seg.png'%(observation_idx))\n",
    "        out_seg = out_seg.squeeze().astype(np.uint8)\n",
    "\n",
    "#         plt.subplot(1, 2, 1)\n",
    "#         plt.imshow(out_img)\n",
    "#         plt.subplot(1, 2, 2)\n",
    "#         plt.imshow(out_seg)\n",
    "\n",
    "#         plt.show()\n",
    "\n",
    "        return out_img, out_seg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** lookat =  [0.  0.  0.1]\n",
      "Logging root =  ../log/mv\n",
      "Processing gmm : 16\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_000.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_001.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_002.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_003.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_004.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_005.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_006.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_007.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_008.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_009.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_010.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_011.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_012.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_013.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_014.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_015.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_016.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_017.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_018.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_019.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_020.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_021.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_022.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_023.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_024.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_025.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_026.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_027.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_028.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_029.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_030.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_031.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_032.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_033.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_034.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_035.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_036.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_037.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_038.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_039.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_040.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_041.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_042.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_043.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_044.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_045.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_046.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_047.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_048.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_049.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_050.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_051.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_052.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_053.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_054.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_055.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_056.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_057.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_058.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_059.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_060.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_061.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_062.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_063.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_064.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_065.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_066.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_067.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_068.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_069.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_070.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_071.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_072.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_073.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_074.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_075.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_076.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_077.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_078.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_079.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_080.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_081.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_082.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_083.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_084.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_085.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_086.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_087.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_088.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_089.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_090.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_091.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_092.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_093.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_094.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_095.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_096.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_097.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_098.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_099.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_100.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_101.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_102.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_103.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_104.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_105.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_106.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_107.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_108.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_109.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_110.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_111.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_112.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_113.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_114.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_115.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_116.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_117.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_118.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_119.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_120.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_121.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_122.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_123.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_124.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_125.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_126.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_127.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_128.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_129.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_130.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_131.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_132.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_133.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_134.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_135.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_136.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_137.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_138.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_139.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_140.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_141.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_142.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_143.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_144.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_145.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_146.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_147.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_148.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_149.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_150.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_151.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_152.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_153.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_154.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_155.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_156.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_157.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_158.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_159.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_160.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_161.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_162.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_163.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_164.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_165.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_166.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_167.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_168.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_169.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_170.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_171.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_172.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_173.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_174.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_175.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_176.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_177.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_178.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_179.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_180.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_181.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_182.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_183.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_184.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_185.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_186.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_187.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_188.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_189.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_190.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_191.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_192.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_193.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_194.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_195.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_196.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_197.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_198.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_199.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_200.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_201.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_202.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_203.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_204.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_205.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_206.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_207.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_208.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_209.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_210.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_211.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_212.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_213.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_214.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_215.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_216.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_217.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_218.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_219.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_220.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_221.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_222.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_223.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_224.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_225.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_226.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_227.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_228.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_229.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_230.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_231.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_232.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_233.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_234.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_235.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_236.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_237.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_238.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_239.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_240.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_241.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_242.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_243.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_244.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_245.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_246.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_247.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_248.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_249.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_250.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_251.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_252.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_253.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_254.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_255.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_256.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_257.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_258.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_259.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_260.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_261.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_262.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_263.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_264.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_265.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_266.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_267.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_268.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_269.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_270.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_271.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_272.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_273.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_274.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_275.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_276.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_277.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_278.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_279.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_280.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_281.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_282.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_283.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_284.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_285.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_286.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_287.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_288.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_289.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_290.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_291.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_292.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_293.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_294.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_295.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_296.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_297.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_298.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_299.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_300.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_301.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_302.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_303.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_304.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_305.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_306.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_307.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_308.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_309.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_310.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_311.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_312.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_313.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_314.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_315.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_316.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_317.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_318.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_319.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_320.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_321.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_322.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_323.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_324.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_325.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_326.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_327.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_328.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_329.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_330.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_331.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_332.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_333.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_334.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_335.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_336.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_337.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_338.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_339.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_340.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_341.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_342.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_343.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_344.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_345.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_346.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_347.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_348.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_349.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_350.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_351.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_352.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_353.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_354.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_355.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_356.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_357.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_358.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_359.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_360.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_361.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_362.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_363.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_364.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_365.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_366.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_367.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_368.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_369.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_370.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_371.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_372.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_373.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_374.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_375.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_376.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_377.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_378.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_379.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_380.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_381.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_382.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_383.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_384.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_385.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_386.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_387.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_388.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_389.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_390.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_391.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_392.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_393.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_394.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_395.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_396.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_397.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_398.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_399.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_400.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_401.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_402.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_403.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_404.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_405.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_406.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_407.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_408.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_409.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_410.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_411.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_412.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_413.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_414.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_415.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_416.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_417.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_418.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_419.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_420.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_421.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_422.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_423.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_424.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_425.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_426.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_427.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_428.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_429.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_430.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_431.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_432.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_433.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_434.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_435.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_436.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_437.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_438.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_439.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_440.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_441.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_442.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_443.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_444.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_445.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_446.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_447.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_448.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_449.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_450.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_451.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_452.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_453.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_454.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_455.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_456.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_457.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_458.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_459.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_460.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_461.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_462.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_463.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_464.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_465.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_466.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_467.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_468.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_469.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_470.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_471.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_472.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_473.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_474.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_475.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_476.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_477.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_478.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_479.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_480.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_481.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_482.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_483.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_484.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_485.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_486.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_487.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_488.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_489.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_490.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_491.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_492.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_493.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_494.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_495.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_496.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_497.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_498.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_499.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_500.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_501.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_502.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_503.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_504.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_505.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_506.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_507.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_508.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_509.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_510.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_511.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_512.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_513.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_514.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_515.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_516.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_517.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_518.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_519.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_520.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_521.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_522.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_523.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_524.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_525.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_526.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_527.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_528.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_529.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_530.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_531.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_532.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_533.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_534.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_535.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_536.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_537.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_538.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_539.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_540.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_541.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_542.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_543.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_544.gif\n",
      "\t [DONE] save vis to :  ../log/mv/vis/16_545.gif\n"
     ]
    }
   ],
   "source": [
    "# render with spiral path\n",
    "\n",
    "import random,os,imageio\n",
    "from scipy.stats import norm\n",
    "\n",
    "def _campos2matrix(cam_pos, cam_center=None, cam_up=None):\n",
    "    _cam_target = np.asarray([0,0.11,0.1]) if cam_center is None else cam_center\n",
    "    _cam_target = _cam_target.reshape((1, 3))\n",
    "    # print('*** cam_center = ', _cam_target.shape)\n",
    "\n",
    "    _cam_up = np.asarray([0.0, 1.0, 0.0]) if cam_up is None else cam_up\n",
    "\n",
    "    cam_dir = (_cam_target-cam_pos)\n",
    "    cam_dir = cam_dir / np.linalg.norm(cam_dir)\n",
    "    cam_right = np.cross(cam_dir, _cam_up)\n",
    "    cam_right = cam_right / np.linalg.norm(cam_right)\n",
    "    cam_up = np.cross(cam_right, cam_dir)\n",
    "\n",
    "    cam_R = np.concatenate([cam_right.T, -cam_up.T, cam_dir.T], axis=1)\n",
    "\n",
    "    cam_P = np.eye(4)\n",
    "    cam_P[:3, :3] = cam_R\n",
    "    cam_P[:3, 3] = cam_pos\n",
    "\n",
    "    return cam_P\n",
    "\n",
    "def render_spiral_path(cam_center,lookat,radii,src_latent,trgt_latent):\n",
    "    # ROTATE\n",
    "    R = np.linalg.norm(cam_center-lookat) + radii[0]\n",
    "\n",
    "    theta = []\n",
    "    theta_range = [0.0, -0.55, 0.55, 0.0]\n",
    "    for i in range(len(theta_range)-1):\n",
    "        theta.append( np.linspace(theta_range[i],theta_range[i+1], num=_INTERP_STEPS))\n",
    "#         theta.append(np.logspace(0.0, 1, 10, endpoint=False)[::-1]/100)\n",
    "    theta = np.concatenate(theta)\n",
    "    x = R*np.sin(theta)\n",
    "    y = np.zeros_like(x)\n",
    "    z = R*np.cos(theta)\n",
    "    cam_T = np.stack([x,y,z],axis=1) + lookat.reshape((1,3))\n",
    "\n",
    "    vis_outputs,out_segs = [],[]\n",
    "    for i in range(len(theta)):\n",
    "        cam_pose = _campos2matrix(cam_T[i], lookat)        \n",
    "        out_img, out_seg = render_scene_cam(model, cam_pose, src_latent, _DEFAULT_CAM_INT, _OUT_SIZE, orthogonal=_ORTHO)  \n",
    "\n",
    "        vis_outputs.append(out_img)\n",
    "        out_segs.append(out_seg)\n",
    "\n",
    "\n",
    "    # SPPIRAL PATH\n",
    "    t = np.linspace(0, 4*np.pi, _INTERP_STEPS*4, endpoint=True)\n",
    "    for k in range(len(t)):\n",
    "        cam_T = np.array([np.cos(t[k]), -np.sin(t[k]), -np.sin(0.5*t[k])]) * radii\n",
    "        cam_T = cam_T[[1,2,0]] + cam_center\n",
    "        cam_pose = _campos2matrix(cam_T, lookat)\n",
    "        out_img, out_seg = render_scene_cam(model, cam_pose, src_latent, _DEFAULT_CAM_INT, _OUT_SIZE, orthogonal=_ORTHO)  \n",
    "        vis_outputs.append(out_img)\n",
    "        out_segs.append(out_seg)\n",
    "\n",
    "    cdf_scale = 1.0/(1.0-norm.cdf(-_INTERP_STEPS//2,0,6)*2)\n",
    "    for idx in range(-_INTERP_STEPS//2,_INTERP_STEPS//2+1):\n",
    "        \n",
    "        _w = (norm.cdf(idx,0,6)-norm.cdf(-_INTERP_STEPS//2,0,6))*cdf_scale\n",
    "        latent = (1.0-_w)*src_latent + _w*trgt_latent\n",
    "        \n",
    "        out_img, out_seg = render_scene_cam(model, cam_pose, latent, _DEFAULT_CAM_INT, _OUT_SIZE, orthogonal=_ORTHO) \n",
    "        vis_outputs.append(out_img)\n",
    "        out_segs.append(out_seg)\n",
    "\n",
    "\n",
    "    for k in range(len(t)):\n",
    "        cam_T = np.array([np.cos(t[k]), -np.sin(t[k]), -np.sin(0.5*t[k])]) * radii\n",
    "        cam_T = cam_T[[1,2,0]] + cam_center\n",
    "        cam_pose = _campos2matrix(cam_T, lookat)\n",
    "        out_img, out_seg = render_scene_cam(model, cam_pose, trgt_latent, _DEFAULT_CAM_INT, _OUT_SIZE, orthogonal=_ORTHO)  \n",
    "        vis_outputs.append(out_img)\n",
    "        out_segs.append(out_seg)\n",
    "\n",
    "    for idx in range(-_INTERP_STEPS//2,_INTERP_STEPS//2+1):\n",
    "        _w = (norm.cdf(idx,0,6)-norm.cdf(-_INTERP_STEPS//2,0,6))*cdf_scale\n",
    "        latent = (1.0-_w)*trgt_latent + _w*src_latent\n",
    "        out_img, out_seg = render_scene_cam(model, cam_pose, latent, _DEFAULT_CAM_INT, _OUT_SIZE, orthogonal=_ORTHO) \n",
    "        vis_outputs.append(out_img)\n",
    "        out_segs.append(out_seg)\n",
    "\n",
    "    return out_segs,vis_outputs\n",
    "\n",
    "def render_uniform_path(cam_center,lookat,radii,src_latent,trgt_latent):\n",
    "    # ROTATE\n",
    "    R = np.linalg.norm(cam_center-lookat) + radii[0]\n",
    "\n",
    "    theta = []\n",
    "    theta_range = [-0.55, 0.55]\n",
    "    for i in range(len(theta_range)-1):\n",
    "        theta.append( np.linspace(theta_range[i],theta_range[i+1], num=_INTERP_STEPS))\n",
    "        \n",
    "    ys = np.linspace(0.3,-0.2,5,endpoint=True)\n",
    "    \n",
    "    theta = np.concatenate(theta)\n",
    "    x = R*np.sin(theta)\n",
    "    z = R*np.cos(theta)\n",
    "    \n",
    "    vis_outputs,out_segs = [],[]\n",
    "    for y in ys:\n",
    "        \n",
    "        cam_T = np.stack([x,np.ones_like(x)*y,z],axis=1) + lookat.reshape((1,3))\n",
    "\n",
    "        for i in range(len(theta)):\n",
    "            cam_pose = _campos2matrix(cam_T[i], lookat)        \n",
    "            out_img, out_seg = render_scene_cam(model, cam_pose, src_latent, _DEFAULT_CAM_INT, _OUT_SIZE, orthogonal=_ORTHO)  \n",
    "            vis_outputs.append(out_img)\n",
    "            out_segs.append(out_seg)\n",
    "\n",
    "    return out_segs,vis_outputs\n",
    "\n",
    "\n",
    "f = 500\n",
    "_DEFAULT_CAM_INT = np.array([[f,0,_IMG_SIZE//2],[0,f,_IMG_SIZE//2],[0,0,1]])\n",
    "\n",
    "lookat = np.asarray([0,0.0,0.1])\n",
    "print('*** lookat = ', lookat)\n",
    "\n",
    "cam_center =  lookat + np.asarray([0, 0, 0.9])\n",
    "cam_up = np.asarray([0.0, 1.0, 0.0])\n",
    "\n",
    "\n",
    "radii, focus_depth = np.asarray([0.1,0.3,0.2]), 4.5 # z,x,y\n",
    "\n",
    "# f = 1200\n",
    "# _DEFAULT_CAM_INT = np.array([[f,0,_IMG_SIZE//2],[0,f,_IMG_SIZE//2],[0,0,1]])\n",
    "\n",
    "# lookat = np.asarray([0,0.0,0.0])\n",
    "# print('*** lookat = ', lookat)\n",
    "\n",
    "# cam_center =  lookat + np.asarray([0., 0.0, 1.2])\n",
    "# cam_up = np.asarray([0.0, -1.0, 0.0])\n",
    "\n",
    "\n",
    "# radii, focus_depth = np.asarray([0.1,0.3,0.2]), 4.5 # z,x,y\n",
    "\n",
    "_LOG_ROOT = os.path.join('../log/mv')\n",
    "os.makedirs(_LOG_ROOT, exist_ok=True)\n",
    "os.makedirs(os.path.join(_LOG_ROOT, 'vis'), exist_ok=True)\n",
    "print('Logging root = ', _LOG_ROOT)\n",
    "\n",
    "_INTERP_STEPS = 3\n",
    "all_instances = list(range(_TOT_NUM_INSTANCES))\n",
    "random.shuffle(all_instances)\n",
    "\n",
    "\n",
    "_ORTHO=False\n",
    "\n",
    "\n",
    "for num_comp in [16]:#, 2, 4, 8, 16\n",
    "    gmm = mixture.GaussianMixture(\n",
    "        n_components=num_comp, covariance_type='full')\n",
    "    gmm.fit(model.latent_codes.weight.data.cpu().numpy())\n",
    "\n",
    "    print('Processing gmm :', num_comp)\n",
    "    \n",
    "    for i in range(1000):\n",
    "\n",
    "#         src_idx = all_instances[i]\n",
    "#         trgt_idx = all_instances[(i+173)%_TOT_NUM_INSTANCES]\n",
    "\n",
    "#         src_latent = model.get_embedding({'instance_idx': torch.LongTensor([src_idx]).squeeze().cuda()}).unsqueeze(0)\n",
    "#         trgt_latent = model.get_embedding({'instance_idx': torch.LongTensor([trgt_idx]).squeeze().cuda()}).unsqueeze(0)\n",
    "\n",
    "        \n",
    "        src_latent = torch.from_numpy(gmm.sample(1)[0]).float()\n",
    "        trgt_latent = torch.from_numpy(gmm.sample(1)[0]).float()\n",
    "    \n",
    "    \n",
    "        output_dir = os.path.join(\n",
    "            _LOG_ROOT, 'gmm_%02d'%(num_comp), '%03d'%(i))\n",
    "        os.makedirs(os.path.join(output_dir), exist_ok=True)\n",
    "\n",
    "#         out_segs,vis_outputs = render_spiral_path(cam_center,lookat,radii,src_latent,trgt_latent)\n",
    "        out_segs,vis_outputs = render_uniform_path(cam_center,lookat,radii,src_latent,trgt_latent)\n",
    "        \n",
    "        \n",
    "        for k,out_seg in enumerate(out_segs):\n",
    "            output_fp = os.path.join(output_dir, '%04d.png'%k)\n",
    "            util.write_img(out_seg, output_fp)\n",
    "        \n",
    "#         for k in np.random.randint(0,len(out_segs),6):\n",
    "#             output_fp = os.path.join(os.path.join(_LOG_ROOT, 'subSample', '%02d_%04d.png'%(i,k)))\n",
    "#             util.write_img(out_segs[k], output_fp)        \n",
    "\n",
    "        vis_fp = os.path.join(_LOG_ROOT, 'vis', '%02d_'%(num_comp)+os.path.basename(output_dir)+'.gif')\n",
    "        print('\\t [DONE] save vis to : ', vis_fp)\n",
    "        imageio.mimsave(vis_fp, vis_outputs, fps=15.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "List = sorted(os.listdir('../log/mv/gmm_16'))\n",
    "os.makedirs(f'/mnt/data/new_disk/chenap/dataset/segmaps/subSample/', exist_ok=True)\n",
    "for folder in List:\n",
    "    ind = np.random.randint(0,15,6)\n",
    "    for i, item in enumerate(ind):\n",
    "        copyfile(f'../log/mv/gmm_16/{folder}/{item:04d}.png', f'/mnt/data/new_disk/chenap/dataset/segmaps//subSample/{folder}_{i:03d}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** lookat =  [0.  0.  0.1]\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/000.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/001.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/002.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/003.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/004.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/005.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/006.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/007.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/008.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/009.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/010.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/011.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/012.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/013.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/014.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/015.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/016.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/017.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/018.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/019.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/020.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/021.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/022.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/023.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/024.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/025.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/026.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/027.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/028.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/029.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/030.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/031.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/032.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/033.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/034.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/035.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/036.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/037.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/038.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/039.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/040.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/041.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/042.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/043.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/044.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/045.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/046.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/047.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/048.gif\n",
      "\t [DONE] save vis to :  ../log/one_to_more/vis/049.gif\n"
     ]
    }
   ],
   "source": [
    "# shape eplotion\n",
    "f = 500\n",
    "_DEFAULT_CAM_INT = np.array([[f,0,_IMG_SIZE//2],[0,f,_IMG_SIZE//2],[0,0,1]])\n",
    "\n",
    "lookat = np.asarray([0,0.0,0.1])\n",
    "print('*** lookat = ', lookat)\n",
    "\n",
    "cam_center =  lookat + np.asarray([0, 0, 0.9])\n",
    "cam_up = np.asarray([0.0, 1.0, 0.0])\n",
    "\n",
    "\n",
    "radii, focus_depth = np.asarray([0.1,0.3,0.2]), 4.5 # z,x,y\n",
    "\n",
    "\n",
    "_INTERP_STEPS = 20\n",
    "all_instances = list(range(_TOT_NUM_INSTANCES))\n",
    "random.shuffle(all_instances)\n",
    "\n",
    "gmm = mixture.GaussianMixture(\n",
    "    n_components=16, covariance_type='full')\n",
    "gmm.fit(model.latent_codes.weight.data.cpu().numpy())\n",
    "\n",
    "cam_center =  lookat + np.asarray([-0.2, 0.0, 1.0])\n",
    "cam_pose = _campos2matrix(cam_center, lookat)\n",
    "\n",
    "_LOG_ROOT = '../log/one_to_more'\n",
    "smile_dir = torch.from_numpy(np.load('/home/anpei/Jack12/MicrosoftAzure/happiness_dir.npy')).float()\n",
    "neutral_dir = torch.from_numpy(np.load('/home/anpei/Jack12/MicrosoftAzure/neutral_dir.npy')).float()\n",
    "\n",
    "\n",
    "\n",
    "for i in range(50):\n",
    "    src_latent = torch.from_numpy(gmm.sample(1)[0]).float()\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    init_img, init_seg = render_scene_cam(model, cam_pose, src_latent, _DEFAULT_CAM_INT, _OUT_SIZE, orthogonal=False)\n",
    "    mouse_count = np.sum(init_seg==8)\n",
    "    direction = smile_dir if np.sum(mouse_count)<20 else neutral_dir\n",
    "#     src_latent -= direction*(mouse_count/40)\n",
    "    frames.append(init_seg)\n",
    "\n",
    "    # expression\n",
    "    _INTERP_STEPS = 6\n",
    "    dst_latent = src_latent.clone()\n",
    "    steps = [0.3/_INTERP_STEPS]*_INTERP_STEPS \n",
    "    for j in steps:\n",
    "        dst_latent += direction*j\n",
    "        out_img, out_seg = render_scene_cam(model, cam_pose, dst_latent, _DEFAULT_CAM_INT, _OUT_SIZE, orthogonal=False)\n",
    "        mask = (out_seg>=2)*(out_seg<=10)\n",
    "\n",
    "        result = np.array(init_seg)\n",
    "        result[(result>=2)*(result<=10)] = 1\n",
    "        result[mask] = out_seg[mask]\n",
    "        frames.append(result)\n",
    "\n",
    "\n",
    "#     # hair\n",
    "#     mask_init = (init_seg>=2)*(init_seg<15)*(init_seg!=11)*(init_seg!=12)\n",
    "#     for direction in [smile_dir,-smile_dir,neutral_dir,-neutral_dir,0.5*smile_dir,-0.5*smile_dir,0.5*neutral_dir,-0.5*neutral_dir]:\n",
    "#         dst_latent = src_latent + direction\n",
    "#         out_img, out_seg = render_scene_cam(model, cam_pose, dst_latent, _DEFAULT_CAM_INT, _OUT_SIZE, orthogonal=False)\n",
    "#         mask = (out_seg>=2)*(out_seg<=10)\n",
    "#         out_seg[mask] = 1\n",
    "#         out_seg[mask_init] = init_seg[mask_init]\n",
    "#         frames.append(out_seg)\n",
    "\n",
    "    # shape\n",
    "    for j in range(4):\n",
    "        direction = torch.from_numpy(gmm.sample(1)[0]).float() - src_latent\n",
    "        dst_latent = src_latent.clone()\n",
    "        steps = [1.0/_INTERP_STEPS]*_INTERP_STEPS\n",
    "        for k in steps:\n",
    "            dst_latent += k*direction\n",
    "            out_img, out_seg = render_scene_cam(model, cam_pose, dst_latent, _DEFAULT_CAM_INT, _OUT_SIZE, orthogonal=False)\n",
    "            frames.append(out_seg)\n",
    "\n",
    "    output_dir = os.path.join( _LOG_ROOT, '%03d'%i)\n",
    "    os.makedirs(os.path.join(output_dir), exist_ok=True)\n",
    "    os.makedirs(os.path.join(_LOG_ROOT,'vis'), exist_ok=True)\n",
    "        \n",
    "    for k,out_seg in enumerate(frames):\n",
    "        output_fp = os.path.join(output_dir, '%04d.png'%k)\n",
    "        util.write_img(out_seg, output_fp)\n",
    "        frames[k] = vis_condition_img(id_remap(out_seg))\n",
    "            \n",
    "    vis_fp = os.path.join(_LOG_ROOT, 'vis', '%03d.gif'%i)\n",
    "    print('\\t [DONE] save vis to : ', vis_fp)\n",
    "    imageio.mimsave(vis_fp, frames, fps=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** lookat =  [0.  0.  0.1]\n",
      "Logging root =  ../log/test\n",
      "\t [DONE] save vis to :  ../log/smile/vis/000.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/001.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/002.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/003.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/004.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/005.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/006.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/007.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/008.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/009.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/010.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/011.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/012.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/013.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/014.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/015.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/016.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/017.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/018.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/019.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/020.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/021.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/022.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/023.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/024.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/025.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/026.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/027.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/028.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/029.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/030.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/031.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/032.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/033.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/034.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/035.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/036.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/037.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/038.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/039.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/040.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/041.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/042.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/043.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/044.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/045.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/046.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/047.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/048.gif\n",
      "\t [DONE] save vis to :  ../log/smile/vis/049.gif\n"
     ]
    }
   ],
   "source": [
    "# smail animate\n",
    "import random,os,imageio\n",
    "from scipy.stats import norm\n",
    "\n",
    "remap_list = np.array([0,1,2,2,3,3,4,5,6,7,8,9,9,10,11,12,13,14,15,16]).astype('float')\n",
    "def id_remap(seg):\n",
    "    return remap_list[seg.astype('int')]\n",
    "\n",
    "def vis_condition_img(img):\n",
    "    part_colors = [[0, 0, 0], [127, 212, 255], [255, 255, 127], [255, 255, 170],#'skin',1 'eye_brow'2,  'eye'3\n",
    "                    [240, 157, 240], [255, 212, 255], #'r_nose'4, 'l_nose'5\n",
    "                    [31, 162, 230], [127, 255, 255], [127, 255, 255],#'mouth'6, 'u_lip'7,'l_lip'8\n",
    "                    [0, 255, 85], [0, 255, 170], #'ear'9 'ear_r'10\n",
    "                    [255, 255, 170],\n",
    "                    [127, 170, 255], [85, 0, 255], [255, 170, 127], #'neck'11, 'neck_l'12, 'cloth'13\n",
    "                    [212, 127, 255], [0, 170, 255],#, 'hair'14, 'hat'15\n",
    "                    [255, 255, 0], [255, 255, 85], [255, 255, 170],\n",
    "                    [255, 0, 255], [255, 85, 255], [255, 170, 255],\n",
    "                    [0, 255, 255], [85, 255, 255], [170, 255, 255], [100, 150, 200]]\n",
    "    H,W = img.shape\n",
    "    condition_img_color = np.zeros((H,W,3)).astype('uint8')\n",
    "\n",
    "    num_of_class = int(np.max(img))\n",
    "    for pi in range(1, num_of_class + 1):\n",
    "        index = np.where(img == pi)\n",
    "        condition_img_color[index[0], index[1],:] = part_colors[pi]\n",
    "    return condition_img_color\n",
    "\n",
    "f = 500\n",
    "_DEFAULT_CAM_INT = np.array([[f,0,_IMG_SIZE//2],[0,f,_IMG_SIZE//2],[0,0,1]])\n",
    "\n",
    "lookat = np.asarray([0,0.0,0.1])\n",
    "print('*** lookat = ', lookat)\n",
    "\n",
    "cam_center =  lookat + np.asarray([0, 0, 0.9])\n",
    "cam_up = np.asarray([0.0, 1.0, 0.0])\n",
    "\n",
    "\n",
    "radii, focus_depth = np.asarray([0.1,0.3,0.2]), 4.5 # z,x,y\n",
    "\n",
    "_LOG_ROOT = os.path.join('../log/test')\n",
    "os.makedirs(_LOG_ROOT, exist_ok=True)\n",
    "os.makedirs(os.path.join(_LOG_ROOT, 'vis'), exist_ok=True)\n",
    "print('Logging root = ', _LOG_ROOT)\n",
    "\n",
    "_INTERP_STEPS = 20\n",
    "all_instances = list(range(_TOT_NUM_INSTANCES))\n",
    "random.shuffle(all_instances)\n",
    "\n",
    "gmm = mixture.GaussianMixture(\n",
    "    n_components=16, covariance_type='full')\n",
    "gmm.fit(model.latent_codes.weight.data.cpu().numpy())\n",
    "\n",
    "cam_pose = _campos2matrix(cam_center, lookat)\n",
    "\n",
    "_LOG_ROOT = '../log/smile'\n",
    "smile_dir = torch.from_numpy(np.load('/home/anpei/Jack12/MicrosoftAzure/happiness_dir.npy')).float()\n",
    "neutral_dir = torch.from_numpy(np.load('/home/anpei/Jack12/MicrosoftAzure/neutral_dir.npy')).float()\n",
    "\n",
    "\n",
    "_INTERP_STEPS = 10\n",
    "for i in range(50):\n",
    "    src_latent = torch.from_numpy(gmm.sample(1)[0]).float()\n",
    "\n",
    "    frames = []\n",
    "\n",
    "#     src_latent -= smile_dir\n",
    "    init_img, init_seg = render_scene_cam(model, cam_pose, src_latent, _DEFAULT_CAM_INT, _OUT_SIZE, orthogonal=False)\n",
    "    mouse_count = np.sum(init_seg==8)\n",
    "    init_seg[(init_seg>=2)*(init_seg<=10)] = 1\n",
    "    \n",
    "\n",
    "    direction = smile_dir if np.sum(mouse_count)<20 else neutral_dir\n",
    "    src_latent -= direction*(mouse_count/200)\n",
    "        \n",
    "    steps = [0.8/_INTERP_STEPS]*_INTERP_STEPS + [-1.0/_INTERP_STEPS]*_INTERP_STEPS\n",
    "    for j in steps:\n",
    "        src_latent += j*direction\n",
    "        out_img, out_seg = render_scene_cam(model, cam_pose, src_latent, _DEFAULT_CAM_INT, _OUT_SIZE, orthogonal=False)\n",
    "        mask = (out_seg>=2)*(out_seg<=10)\n",
    "\n",
    "        result = np.array(init_seg)\n",
    "        result[mask] = out_seg[mask]\n",
    "        frames.append(result)\n",
    "\n",
    "    output_dir = os.path.join( _LOG_ROOT, '%03d'%i)\n",
    "    os.makedirs(os.path.join(output_dir), exist_ok=True)\n",
    "    os.makedirs(os.path.join(_LOG_ROOT,'vis'), exist_ok=True)\n",
    "        \n",
    "    for k,out_seg in enumerate(frames):\n",
    "        output_fp = os.path.join(output_dir, '%04d.png'%k)\n",
    "        util.write_img(out_seg, output_fp)\n",
    "        frames[k] = vis_condition_img(id_remap(out_seg))\n",
    "            \n",
    "    vis_fp = os.path.join(_LOG_ROOT, 'vis', '%03d.gif'%i)\n",
    "    #print('\\t [DONE] save vis to : ', vis_fp)\n",
    "    imageio.mimsave(vis_fp, frames, fps=5.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** lookat =  [0.  0.  0.1]\n",
      "Logging root =  ../log/test\n",
      "\t [DONE] save vis to :  ../log/hair/vis/000.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/001.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/002.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/003.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/004.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/005.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/006.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/007.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/008.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/009.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/010.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/011.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/012.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/013.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/014.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/015.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/016.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/017.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/018.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/019.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/020.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/021.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/022.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/023.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/024.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/025.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/026.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/027.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/028.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/029.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/030.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/031.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/032.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/033.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/034.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/035.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/036.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/037.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/038.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/039.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/040.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/041.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/042.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/043.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/044.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/045.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/046.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/047.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/048.gif\n",
      "\t [DONE] save vis to :  ../log/hair/vis/049.gif\n"
     ]
    }
   ],
   "source": [
    "# hair\n",
    "\n",
    "f = 500\n",
    "_DEFAULT_CAM_INT = np.array([[f,0,_IMG_SIZE//2],[0,f,_IMG_SIZE//2],[0,0,1]])\n",
    "\n",
    "lookat = np.asarray([0,0.0,0.1])\n",
    "print('*** lookat = ', lookat)\n",
    "\n",
    "cam_center =  lookat + np.asarray([0, 0, 0.9])\n",
    "cam_up = np.asarray([0.0, 1.0, 0.0])\n",
    "\n",
    "\n",
    "radii, focus_depth = np.asarray([0.1,0.3,0.2]), 4.5 # z,x,y\n",
    "\n",
    "_LOG_ROOT = os.path.join('../log/test')\n",
    "os.makedirs(_LOG_ROOT, exist_ok=True)\n",
    "os.makedirs(os.path.join(_LOG_ROOT, 'vis'), exist_ok=True)\n",
    "print('Logging root = ', _LOG_ROOT)\n",
    "\n",
    "_INTERP_STEPS = 20\n",
    "all_instances = list(range(_TOT_NUM_INSTANCES))\n",
    "random.shuffle(all_instances)\n",
    "\n",
    "gmm = mixture.GaussianMixture(\n",
    "    n_components=16, covariance_type='full')\n",
    "gmm.fit(model.latent_codes.weight.data.cpu().numpy())\n",
    "\n",
    "cam_pose = _campos2matrix(cam_center, lookat)\n",
    "\n",
    "_LOG_ROOT = '../log/hair'\n",
    "smile_dir = torch.from_numpy(np.load('/home/anpei/Jack12/MicrosoftAzure/happiness_dir.npy')).float()*0.8\n",
    "neutral_dir = torch.from_numpy(np.load('/home/anpei/Jack12/MicrosoftAzure/neutral_dir.npy')).float()\n",
    "\n",
    "\n",
    "_INTERP_STEPS = 10\n",
    "for i in range(50):\n",
    "    src_latent = torch.from_numpy(gmm.sample(1)[0]).float()\n",
    "\n",
    "    frames = []\n",
    "\n",
    "#     src_latent -= smile_dir\n",
    "    init_img, init_seg = render_scene_cam(model, cam_pose, src_latent, _DEFAULT_CAM_INT, _OUT_SIZE, orthogonal=False)\n",
    "    mouse_count = np.sum(init_seg==8)\n",
    "    mask_init = (init_seg>=2)*(init_seg<=15)*(init_seg!=11)*(init_seg!=12)\n",
    "    \n",
    "\n",
    "    direction = smile_dir if np.sum(mouse_count)<20 else neutral_dir\n",
    "    src_latent -= direction*(mouse_count/200)\n",
    "        \n",
    "    steps = [1.0/_INTERP_STEPS]*_INTERP_STEPS + [-1.0/_INTERP_STEPS]*_INTERP_STEPS\n",
    "    for j in steps:\n",
    "        src_latent += j*direction\n",
    "        out_img, out_seg = render_scene_cam(model, cam_pose, src_latent, _DEFAULT_CAM_INT, _OUT_SIZE, orthogonal=False)\n",
    "        mask = (out_seg>=2)*(out_seg<=10)\n",
    "\n",
    "        out_seg[mask] = 1\n",
    "        out_seg[mask_init] = init_seg[mask_init]\n",
    "        frames.append(out_seg)\n",
    "\n",
    "    output_dir = os.path.join( _LOG_ROOT, '%03d'%i)\n",
    "    os.makedirs(os.path.join(output_dir), exist_ok=True)\n",
    "    os.makedirs(os.path.join(_LOG_ROOT,'vis'), exist_ok=True)\n",
    "        \n",
    "    for k,out_seg in enumerate(frames):\n",
    "        output_fp = os.path.join(output_dir, '%04d.png'%k)\n",
    "        util.write_img(out_seg, output_fp)\n",
    "        frames[k] = vis_condition_img(id_remap(out_seg))\n",
    "            \n",
    "    vis_fp = os.path.join(_LOG_ROOT, 'vis', '%03d.gif'%i)\n",
    "    #print('\\t [DONE] save vis to : ', vis_fp)\n",
    "    imageio.mimsave(vis_fp, frames, fps=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** lookat =  [0.  0.  0.1]\n",
      "Logging root =  ../log/test\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-83ee7a9d959a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0m_INTERP_STEPS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mall_instances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_TOT_NUM_INSTANCES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_instances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m gmm = mixture.GaussianMixture(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "# shape\n",
    "\n",
    "f = 500\n",
    "_DEFAULT_CAM_INT = np.array([[f,0,_IMG_SIZE//2],[0,f,_IMG_SIZE//2],[0,0,1]])\n",
    "\n",
    "lookat = np.asarray([0,0.0,0.1])\n",
    "print('*** lookat = ', lookat)\n",
    "\n",
    "cam_center =  lookat + np.asarray([0, 0, 0.9])\n",
    "cam_up = np.asarray([0.0, 1.0, 0.0])\n",
    "\n",
    "\n",
    "radii, focus_depth = np.asarray([0.1,0.3,0.2]), 4.5 # z,x,y\n",
    "\n",
    "_LOG_ROOT = os.path.join('../log/test')\n",
    "os.makedirs(_LOG_ROOT, exist_ok=True)\n",
    "os.makedirs(os.path.join(_LOG_ROOT, 'vis'), exist_ok=True)\n",
    "print('Logging root = ', _LOG_ROOT)\n",
    "\n",
    "_INTERP_STEPS = 20\n",
    "all_instances = list(range(_TOT_NUM_INSTANCES))\n",
    "random.shuffle(all_instances)\n",
    "\n",
    "gmm = mixture.GaussianMixture(\n",
    "    n_components=16, covariance_type='full')\n",
    "gmm.fit(model.latent_codes.weight.data.cpu().numpy())\n",
    "\n",
    "cam_pose = _campos2matrix(cam_center, lookat)\n",
    "\n",
    "_LOG_ROOT = '../log/shape'\n",
    "\n",
    "\n",
    "_INTERP_STEPS = 10\n",
    "for i in range(50):\n",
    "    src_latent = torch.from_numpy(gmm.sample(1)[0]).float()\n",
    "    dst_latent = torch.from_numpy(gmm.sample(1)[0]).float()\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    driection = dst_latent - src_latent\n",
    "    steps = [1.0/_INTERP_STEPS]*_INTERP_STEPS + [-1.0/_INTERP_STEPS]*_INTERP_STEPS\n",
    "    for j in steps:\n",
    "        src_latent += j*direction\n",
    "        out_img, out_seg = render_scene_cam(model, cam_pose, src_latent, _DEFAULT_CAM_INT, _OUT_SIZE, orthogonal=False)\n",
    "        frames.append(out_seg)\n",
    "\n",
    "    output_dir = os.path.join( _LOG_ROOT, '%03d'%i)\n",
    "    os.makedirs(os.path.join(output_dir), exist_ok=True)\n",
    "    os.makedirs(os.path.join(_LOG_ROOT,'vis'), exist_ok=True)\n",
    "        \n",
    "    for k,out_seg in enumerate(frames):\n",
    "        output_fp = os.path.join(output_dir, '%04d.png'%k)\n",
    "        util.write_img(out_seg, output_fp)\n",
    "        frames[k] = vis_condition_img(id_remap(out_seg))\n",
    "            \n",
    "    vis_fp = os.path.join(_LOG_ROOT, 'vis', '%03d.gif'%i)\n",
    "    #print('\\t [DONE] save vis to : ', vis_fp)\n",
    "    imageio.mimsave(vis_fp, frames, fps=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vis all instances\n",
    "\n",
    "import random,os\n",
    "\n",
    "_LOG_ROOT = os.path.join(os.getenv(\"HOME\"), 'liury/log/SRNs/test', 'custo_070821face_seg_800_imae')\n",
    "os.makedirs(os.path.join(_LOG_ROOT, 'vis'), exist_ok=True)\n",
    "print('Logging root = ', _LOG_ROOT)\n",
    "\n",
    "_INTERP_STEPS = 2\n",
    "all_instances = list(range(_TOT_NUM_INSTANCES))\n",
    "for i in range(1):\n",
    "\n",
    "    lat_idx = [all_instances[i], random.choice(all_instances)]\n",
    "    src_idx = all_instances[i]\n",
    "    \n",
    "    src_latent = model.get_embedding({'instance_idx': torch.LongTensor([src_idx]).squeeze().cuda()}).unsqueeze(0)\n",
    "    \n",
    "    cam_K = '../checkpoints/intrinsics.txt'\n",
    "    cam_int = data_util.parse_intrinsics(cam_K, trgt_sidelength=128)\n",
    "    focal = cam_int[0, 0]\n",
    "    cx, cy = cam_int[:2, 2]\n",
    "\n",
    "    cam_center = np.asarray([0., 0.11, 0.1])\n",
    "    cam_T = np.asarray([0.0, 0.0, 1.0]) + cam_center\n",
    "    cam_pose = _campos2matrix(cam_T, cam_center)\n",
    "    print(cam_pose)\n",
    "\n",
    "\n",
    "    latent = src_latent \n",
    "\n",
    "    out_img, out_seg = render_scene(model, cam_pose, latent, focal, _OUT_SIZE)        \n",
    "\n",
    "    vis_fp = os.path.join(_LOG_ROOT, 'vis','%04d.png'%src_idx)\n",
    "#     print('[DONE] save vis to : ', vis_fp)\n",
    "    util.write_img(out_img[...,::-1], vis_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** lookat =  [0 0 0]\n",
      "Logging root =  /home/anpei/liury/log/SRNs/test/spiral_gmm\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_addmm",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-2c938a05cb49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m out_img, out_seg = render_scene_cam(\n\u001b[0;32m---> 27\u001b[0;31m     model, _campos2matrix(cam_center, lookat, cam_up), z, _DEFAULT_CAM_INT, _OUT_SIZE)\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-65-7fb4136de428>\u001b[0m in \u001b[0;36mrender_scene_cam\u001b[0;34m(model, pose, z, cam_int, img_sidelength)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m#         print(pose.shape, cam_int.shape, uv.shape, z.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_maps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcam_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/srns/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/data/new_disk2/liury/code/SRNs/modeling/srns.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, pose, z, intrinsics, uv, dpt, dpt_scale, device, auc_input)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatent_reg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;31m# Forward pass through hypernetwork yields a (callable) SRN.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m         \u001b[0mphi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyper_phi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;31m# print('*** 2: ray_marcher.')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/srns/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/data/new_disk2/liury/code/SRNs/layers/hyperlayers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hyper_input)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyper_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/srns/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/data/new_disk2/liury/code/SRNs/layers/hyperlayers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hyper_input)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mfully\u001b[0m \u001b[0mconnected\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         '''\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyper_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyper_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_nl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/srns/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/data/new_disk2/liury/code/SRNs/layers/hyperlayers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hyper_input)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyper_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0mhypo_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypo_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyper_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;31m# Indices explicit to catch erros in shape of output layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/srns/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/data/new_disk2/liury/code/SRNs/layers/pytorch_prototyping.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/srns/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/srns/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/srns/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/data/new_disk2/liury/code/SRNs/layers/pytorch_prototyping.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/srns/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/srns/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/srns/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/srns/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/srns/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1608\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1610\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1611\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_addmm"
     ]
    }
   ],
   "source": [
    "_DEFAULT_CAM_INT = np.load(\n",
    "    '/home/anpei/liury/data/facial-data/seg_face_real/intrinsics_avg.npy')\n",
    "\n",
    "f = 30\n",
    "_DEFAULT_CAM_INT = np.array([[f,0,_IMG_SIZE//2],[0,f,_IMG_SIZE//2],[0,0,1]])\n",
    "\n",
    "\n",
    "lookat = np.asarray([0, 0, 0])\n",
    "print('*** lookat = ', lookat)\n",
    "\n",
    "cam_center =  np.asarray([0, 0, 2.2])\n",
    "cam_up = np.asarray([0.0, -1.0, 0.0])\n",
    "\n",
    "radii, focus_depth = np.asarray([0.1,0.3,0.2]), 4.5 # z,x,y\n",
    "\n",
    "_LOG_ROOT = os.path.join(os.getenv(\"HOME\"), 'liury/log/SRNs/test', 'spiral_gmm')\n",
    "os.makedirs(os.path.join(_LOG_ROOT, 'vis'), exist_ok=True)\n",
    "print('Logging root = ', _LOG_ROOT)\n",
    "\n",
    "_INTERP_STEPS = 15\n",
    "all_instances = list(range(_TOT_NUM_INSTANCES))\n",
    "random.shuffle(all_instances)\n",
    "\n",
    "# test camera pose\n",
    "z = torch.from_numpy(gmm.sample(1)[0]).float().cuda()\n",
    "out_img, out_seg = render_scene_cam(\n",
    "    model, _campos2matrix(cam_center, lookat, cam_up), z, _DEFAULT_CAM_INT, _OUT_SIZE)\n",
    "\n",
    "\n",
    "plt.imshow(out_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DEFAULT_CAM_INT = '../checkpoints/intrinsics.txt'\n",
    "_LOG_ROOT = os.path.join(os.getenv(\"HOME\"), 'liury/log/SRNs')\n",
    "\n",
    "cam_int = data_util.parse_intrinsics(_DEFAULT_CAM_INT, trgt_sidelength=128)\n",
    "focal = cam_int[0, 0]\n",
    "cam_center = np.array([0,0.11,0.1])\n",
    "\n",
    "\n",
    "for i in range(150):\n",
    "    lat_idx = torch.randint(0, _TOT_NUM_INSTANCES, (2,)).squeeze().cuda()\n",
    "    src_latent = model.get_embedding({'instance_idx': lat_idx[0]}).unsqueeze(0)\n",
    "    trgt_latent = model.get_embedding({'instance_idx': lat_idx[1]}).unsqueeze(0)\n",
    "    \n",
    "    src_idx = lat_idx[0].cpu().numpy()\n",
    "    trgt_idx = lat_idx[1].cpu().numpy()\n",
    "        \n",
    "    output_dir = os.path.join(\n",
    "        _LOG_ROOT, 'interp_latent', 's%04d_t%04d'%(src_idx, trgt_idx))\n",
    "    os.makedirs(os.path.join(output_dir, 'seg'), exist_ok=True)\n",
    "    \n",
    "    print('[%02d] %04d -> %04d: %s'%(i, src_idx, trgt_idx, output_dir))\n",
    "    \n",
    "    R = np.random.rand()*0.5 + 0.7\n",
    "    theta = np.random.rand()*0.4 + (np.pi/2-0.2)\n",
    "    phi = np.random.rand()*1.2 + (np.pi/2-0.6)\n",
    "    \n",
    "    x = R * np.sin(theta) * np.cos(phi)\n",
    "    y = R * np.sin(theta) * np.sin(phi)\n",
    "    z = R * np.cos(theta)\n",
    "    \n",
    "    cam_pose = _campos2matrix(np.array([x, z, y])+cam_center, cam_center)\n",
    "    \n",
    "    steps = 30\n",
    "    \n",
    "    img_outputs = []    \n",
    "    \n",
    "    for idx in range(steps):\n",
    "        _w = float(idx) / (steps - 1)\n",
    "        latent = (1.0-_w)*src_latent + _w*trgt_latent\n",
    "        \n",
    "        out_img, out_seg = render_scene(model, cam_pose, latent, focal, _OUT_SIZE)\n",
    "        \n",
    "        img_outputs.append(out_img)\n",
    "        output_fp = os.path.join(output_dir, '%04d.png'%(idx))\n",
    "        util.write_img(out_seg, output_fp)\n",
    "        \n",
    "    imageio.mimsave(os.path.join(output_dir, 'output.gif'), img_outputs, fps=10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load latent\n",
    "from glob import glob\n",
    "from torchvision.utils import make_grid\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "\n",
    "from dataset import data_util\n",
    "from dataset.data_util import load_seg_map\n",
    "\n",
    "_ORI_DATA_ROOT = '/mnt/new_disk2/liury/data/facial-data/CelebAMask-HQ/segmap_20'\n",
    "_LOG_ROOT = os.path.join(os.getenv(\"HOME\"), 'liury/log/SRNs')\n",
    "_LATENT_ROOT = os.path.join(_LOG_ROOT, '060115face_celebA/latent_codes')\n",
    "\n",
    "all_latents = glob(os.path.join(_LATENT_ROOT, '*.npy'))\n",
    "\n",
    "print('tot latents: ', len(all_latents))\n",
    "\n",
    "_DEFAULT_CAM_INT = '../checkpoints/intrinsics.txt'\n",
    "cam_int = data_util.parse_intrinsics(_DEFAULT_CAM_INT, trgt_sidelength=128)\n",
    "focal = cam_int[0, 0]\n",
    "cam_center = np.array([0,0.11,0.0])\n",
    "\n",
    "for i in range(27, len(all_latents)):\n",
    "    out_imgs = []    \n",
    "    \n",
    "    item_id = int(os.path.basename(all_latents[i]).split('.')[0].split('_')[1])\n",
    "    latent = np.load(all_latents[i])\n",
    "    \n",
    "    # load ori\n",
    "    ori_seg = torch.from_numpy(load_seg_map(os.path.join(_ORI_DATA_ROOT, '%d.png'%(item_id)), _OUT_SIZE))\n",
    "    ori_seg_img = util.lin2img(ori_seg.unsqueeze(0), color_map=_CMAP).cpu().numpy()\n",
    "    ori_seg_img = (ori_seg_img.squeeze().transpose(1, 2, 0)) * 255.0\n",
    "    ori_seg_img = ori_seg_img.round().clip(0, 255).astype(np.uint8)\n",
    "    out_imgs.append(torch.from_numpy(ori_seg_img).permute(2, 0, 1).unsqueeze(0))\n",
    "        \n",
    "    # predict\n",
    "    cam_T = latent[:3]\n",
    "    latent = torch.from_numpy(latent[3:]).unsqueeze(0).cuda()\n",
    "    R = np.linalg.norm(cam_T)\n",
    "\n",
    "    cam_pose = _campos2matrix(cam_T+cam_center, cam_center)\n",
    "    out_img, out_seg = render_scene(model, cam_pose, latent, focal, _OUT_SIZE)\n",
    "    out_imgs.append(torch.from_numpy(out_img).permute(2, 0, 1).unsqueeze(0))\n",
    "    \n",
    "    # calc mIoU\n",
    "    ori_seg = F.one_hot(ori_seg.squeeze().long(), 20)\n",
    "    out_seg = F.one_hot(torch.from_numpy(out_seg).flatten().long(), 20)\n",
    "    \n",
    "    print(ori_seg.shape, out_seg.shape)\n",
    "    break\n",
    "    \n",
    "    mIoU = torch.mean(torch.div(\n",
    "        torch.sum(ori_seg&out_seg, dim=0).float()+1e-8,\n",
    "        torch.sum(ori_seg|out_seg, dim=0).float()+1e-8))\n",
    "                \n",
    "    for step in range(6):\n",
    "    \n",
    "        theta = np.random.rand()*0.4 + (np.pi/2-0.2)\n",
    "        phi = np.random.rand()*1.2 + (np.pi/2-0.6)\n",
    "\n",
    "        x = R * np.sin(theta) * np.cos(phi)\n",
    "        y = R * np.sin(theta) * np.sin(phi)\n",
    "        z = R * np.cos(theta)\n",
    "\n",
    "        cam_pose = _campos2matrix(np.array([x, z, y])+cam_center, cam_center)\n",
    "        out_img, out_seg = render_scene(model, cam_pose, latent, focal, _OUT_SIZE)\n",
    "                \n",
    "        out_imgs.append(torch.from_numpy(out_img).permute(2, 0, 1).unsqueeze(0))\n",
    "    \n",
    "        \n",
    "    out_imgs = make_grid(torch.cat(out_imgs), nrow=8, padding=1).permute((1, 2, 0)).cpu().numpy()\n",
    "    \n",
    "    ############## vis ##################    \n",
    "    fig = plt.figure(figsize=(45, 5))\n",
    "    plt.imshow(out_imgs)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    ####################################\n",
    "    \n",
    "    output_dir = os.path.join(_LOG_ROOT, 'change_view_celebA', '%06d'%(item_id))\n",
    "    os.makedirs(os.path.join(output_dir, 'seg'), exist_ok=True)    \n",
    "    render_custo_path(0, latent, cam_center=cam_center, output_dir=output_dir)\n",
    "    \n",
    "    print('[%06d] %d : R = %f, mIoU = %f, output_dir = %s'%(i, item_id, R, mIoU, output_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = torch.cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    lat_idx = torch.randint(0, _TOT_NUM_INSTANCES, (2,)).squeeze().cuda()\n",
    "    src_latent = model.get_embedding({'instance_idx': lat_idx[0]}).unsqueeze(0)\n",
    "    trgt_latent = model.get_embedding({'instance_idx': lat_idx[1]}).unsqueeze(0)\n",
    "    \n",
    "    src_idx = lat_idx[0].cpu().numpy()\n",
    "    trgt_idx = lat_idx[1].cpu().numpy()\n",
    "    \n",
    "    print('%02d: %04d -> %04d'%(i, src_idx, trgt_idx))\n",
    "    \n",
    "    output_dir = os.path.join(\n",
    "        _LOG_ROOT, 'out_mode_3', 's%04d_t%04d'%(src_idx, trgt_idx))\n",
    "    os.makedirs(os.path.join(output_dir, 'seg'), exist_ok=True)\n",
    "    \n",
    "    print(output_dir)\n",
    "    \n",
    "    render_custo_path(0, src_latent, trgt_latent, output_dir=output_dir)\n",
    "\n",
    "    cam_pose = _campos2matrix(np.array([0., 0., 0.8])+cam_center, cam_center)\n",
    "    out_img, out_seg = render_scene(model, cam_pose, _get_latent(i), focal, _OUT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.face_dataset import FaceRandomPoseDataset\n",
    "from torch.utils.data import DataLoader\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import cv2\n",
    "import imageio\n",
    "\n",
    "_OUTPUT_DIR = os.path.join(_LOG_ROOT, 'output_iter_020000')\n",
    "_MODE = 'sphere'\n",
    "_R = 1.5\n",
    "\n",
    "\n",
    "_NUM_INSTANCES=10\n",
    "_NUM_OBSERVATIONS=25\n",
    "\n",
    "output_dir = os.path.join(_OUTPUT_DIR, _MODE+'_128')\n",
    "sample_instances = list(np.random.choice(range(_TOT_NUM_INSTANCES), _NUM_INSTANCES, replace=False))\n",
    "\n",
    "# writer = SummaryWriter(output_dir)\n",
    "\n",
    "dataset = FaceRandomPoseDataset(\n",
    "    intrinsics=_CAM_INT,\n",
    "    cam_center=_CAM_CENTER,\n",
    "    num_instances=sample_instances, \n",
    "    num_observations=_NUM_OBSERVATIONS, \n",
    "    sample_radius=_R, mode=_MODE)\n",
    "\n",
    "dataloader = DataLoader(dataset,\n",
    "                     collate_fn=dataset.collate_fn,\n",
    "                     batch_size=1,\n",
    "                     shuffle=False,\n",
    "                     drop_last=False)\n",
    "\n",
    "print('Beginning evaluation...')\n",
    "\n",
    "images = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for idx, model_input in enumerate(dataloader):\n",
    "        model_input, ground_truth = model_input\n",
    "        \n",
    "        pose = model_input['pose']\n",
    "        \n",
    "#         print(pose)\n",
    "        \n",
    "        intrinsics = model_input['intrinsics']\n",
    "        uv = model_input['uv']\n",
    "        z = model.get_embedding(model_input)\n",
    "        \n",
    "        model_outputs = model(pose, z, intrinsics, uv)\n",
    "        predictions, depth_maps = model_outputs\n",
    "                \n",
    "        batch_size, tensor_len, channels = predictions.shape\n",
    "        img_sidelen = np.sqrt(tensor_len).astype(int)\n",
    "                \n",
    "        pred = torch.argmax(predictions, dim=2, keepdim=True)\n",
    "        output_img = util.lin2img(pred, color_map=).cpu().numpy()\n",
    "        output_pred = pred.view(batch_size, img_sidelen, img_sidelen, 1).cpu().numpy()\n",
    "\n",
    "        for i in range(output_img.shape[0]):\n",
    "            instance_idx = int(model_input['instance_idx'][i].squeeze().detach().cpu().numpy().astype(np.int64))\n",
    "            observation_idx = model_input['observation_idx'][i]\n",
    "            \n",
    "            instance_dir = os.path.join(output_dir, \"%03d\" % instance_idx)\n",
    "            os.makedirs(instance_dir, exist_ok=True)\n",
    "            \n",
    "            img = output_img[i, :, :, :].squeeze().transpose(1, 2, 0)\n",
    "            img *= 255\n",
    "            img = img.round().clip(0, 255).astype(np.uint8)\n",
    "#             img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n",
    "\n",
    "            if not instance_idx in images:\n",
    "                images[instance_idx] = [None] * _NUM_OBSERVATIONS\n",
    "\n",
    "            images[instance_idx][observation_idx] = img\n",
    "#             output_fp = os.path.join(instance_dir, '%02d.png'%(observation_idx))\n",
    "#             util.write_img(img, output_fp)\n",
    "            \n",
    "            output_fp = os.path.join(instance_dir, '%02d_seg.png'%(observation_idx))\n",
    "            seg_img = output_pred[i, :, :].squeeze().astype(np.uint8)\n",
    "            \n",
    "            util.write_img(seg_img, output_fp)\n",
    "            \n",
    "#             dpt_img = (output_dpt[i, :, :, :].squeeze() * 255.0).astype(np.uint8)\n",
    "#             dpt_img = cv2.applyColorMap(dpt_img, cv2.COLORMAP_JET)\n",
    "#             output_fp = os.path.join(instance_dir, '%02d_depth.png'%(observation_idx))\n",
    "# #             print('Save output for instance %03d - %02d: %s'%(instance_idx, observation_idx, output_fp))\n",
    "#             util.write_img(dpt_img, output_fp)\n",
    "            print('Save output for instance %04d - %02d: %s'%(instance_idx, observation_idx, output_fp))\n",
    "        \n",
    "            if observation_idx == _NUM_OBSERVATIONS - 1:\n",
    "                imageio.mimsave(os.path.join(instance_dir, 'output.gif'), images[instance_idx], fps=5.0)\n",
    "                print('=== [DONE] saving output.gif.')\n",
    "            \n",
    "#         print('[DONE] Save output for instance %03d.'%(instance_idx))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# move seg_face_8000\n",
    "import os\n",
    "from glob import glob\n",
    "from shutil import copyfile\n",
    "\n",
    "data_root = '/data/anpei/facial-data/seg_face_8000/images'\n",
    "img_fps = glob(os.path.join(data_root, '*_seg_*.png'))\n",
    "img_ids = list(set([os.path.basename(x)[:5] for x in img_fps]))\n",
    "\n",
    "for img_id in img_ids:\n",
    "    output_dir = os.path.join(data_root, img_id)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    copyfile(\n",
    "        os.path.join(data_root, '..', 'cam2world.npy'), \n",
    "        os.path.join(output_dir, 'cam2world.npy'))\n",
    "    \n",
    "    img_fps = glob(os.path.join(data_root, '%s_seg_*.png'%(img_id)))\n",
    "    print(output_dir, len(imgs))\n",
    "    for img_fp in sorted(img_fps):\n",
    "        out_name = os.path.basename(img_fp).split('_')\n",
    "        out_sub_dir = out_name[0]\n",
    "        out_name = '_'.join([out_name[1], '%02d'%(int(out_name[-2])*5+int(out_name[-1][:2]))]) + '.png'\n",
    "        out_name = os.path.join(os.path.dirname(img_fp), out_sub_dir, out_name)\n",
    "#         print('\\t> ', img_fp, out_name)\n",
    "        os.rename(img_fp, out_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "data_dir = '/data/anpei/facial-data/seg_face_2000/10996'\n",
    "\n",
    "cam_param = np.load(os.path.join(data_dir, 'cameras.npy'), allow_pickle=True).item() \n",
    "print(np.asarray(cam_param['zRange']).shape, np.asarray(cam_param['extrinsics']).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as torch_models\n",
    "import torch\n",
    "\n",
    "resnet_model = torch_models.resnet18(pretrained=False)\n",
    "# resnet_model.layer4 = torch.nn.Identity()\n",
    "# resnet_model.fc = torch.nn.Identity()\n",
    "resnet_model.conv1 = torch.nn.Conv2d(19, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "print(resnet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = resnet_model(torch.Tensor(8, 19, 128, 128))\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "aa = torch.randint(0, 19, size=(1, 3, 3))\n",
    "print(aa.shape)\n",
    "\n",
    "bb = F.one_hot(aa)\n",
    "print(bb.shape, bb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = torch.empty(256)\n",
    "print(aa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "instance_dir = '/data/anpei/facial-data/seg_body/94'\n",
    "seg_imgs = img = cv2.imread(os.path.join(instance_dir, 'semantic_mask', 'image.cam05_000094.png'), cv2.IMREAD_UNCHANGED).astype(np.float32)\n",
    "print(np.unique(seg_imgs))\n",
    "\n",
    "\n",
    "fs = cv2.FileStorage(\"/data/anpei/facial-data/seg_body/Calib_T_samba/cam05_000000/intrinsic.xml\", cv2.FILE_STORAGE_READ)\n",
    "intrinsics = fs.getNode(\"M\").mat()\n",
    "\n",
    "print(intrinsics)\n",
    "\n",
    "H, W = seg_imgs.shape\n",
    "cx, cy = intrinsics[:2, 2]\n",
    "\n",
    "x_coord, y_coord = np.where(seg_imgs != 0)\n",
    "bbox = np.asarray([np.min(x_coord), np.min(y_coord), np.max(x_coord), np.max(y_coord)])\n",
    "print(bbox)\n",
    "\n",
    "sidelength = max(bbox[2] - bbox[0], bbox[3] - bbox[1])\n",
    "center = np.asarray([bbox[2] + bbox[0], bbox[3] + bbox[1]]) / 2.0\n",
    "bbox = np.ceil(np.asarray([\n",
    "    center[0]-sidelength/2.0, \n",
    "    center[1]-sidelength/2.0, \n",
    "    center[0]+sidelength/2.0,\n",
    "    center[1]+sidelength/2.0])).astype(np.int64)\n",
    "\n",
    "cx, cy = intrinsics[:2, 2] - bbox[:2]\n",
    "\n",
    "print(bbox, bbox.dtype)\n",
    "seg_imgs = seg_imgs[bbox[0]:bbox[2], bbox[1]:bbox[3]]\n",
    "print(seg_imgs.shape)\n",
    "\n",
    "\n",
    "print(cx, cy, bbox)\n",
    "intrinsics[:2, 2] = [cx, cy]\n",
    "print(intrinsics)\n",
    "\n",
    "\n",
    "print(H, W, cx, cy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.body_dataset import BodyPartDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "import util\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "dataset = BodyPartDataset(\n",
    "        data_type='seg',\n",
    "        img_sidelength=128, \n",
    "        sample_observations=list(range(5)),\n",
    "        sample_instances=list(range(2)))\n",
    "\n",
    "dataloader = DataLoader(dataset,\n",
    "                     collate_fn=dataset.collate_fn,\n",
    "                     batch_size=1,\n",
    "                     shuffle=False,\n",
    "                     drop_last=False)\n",
    "\n",
    "print(len(dataloader))\n",
    "\n",
    "for idx, model_input in enumerate(dataloader):\n",
    "    model_input, ground_truth = model_input\n",
    "        \n",
    "    seg_img = model_input['rgb']\n",
    "    pose = model_input['pose']\n",
    "    intrinsics = model_input['intrinsics']\n",
    "    uv = model_input['uv']    \n",
    "    \n",
    "    print('> ', np.unique(seg_img), seg_img.shape)\n",
    "    print('> pose = ')\n",
    "    print(pose)\n",
    "    print('> cam_int = ')\n",
    "    print(intrinsics)\n",
    "    print(seg_img.shape, np.unique(seg_img))\n",
    "    \n",
    "    output_img = util.lin2img(seg_img, color_map=dataset.color_map).cpu().numpy()\n",
    "    \n",
    "    plt.imshow(output_img.squeeze().transpose(1, 2, 0))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "model = models.resnet18(pretrained=False)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "H, W = 512, 512\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(   self, \n",
    "                    in_channels, \n",
    "                    out_channels, \n",
    "                    kernel_size=3, \n",
    "                    stride=1, \n",
    "                    num_groups=2):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, stride//2),\n",
    "            nn.GroupNorm(num_groups, out_channels),\n",
    "            nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "    \n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        \n",
    "        self.conv1_1 = ConvBlock(in_channels, 8, 3, 1)\n",
    "        self.conv1_2 = ConvBlock(8, 16, 3, 2)\n",
    "        self.conv2_1 = ConvBlock(16, 16, 3, 1)\n",
    "        self.conv2_2 = ConvBlock(16, 32, 3, 2)\n",
    "        self.conv3_1 = ConvBlock(32, 32, 3, 1)\n",
    "        self.deconv4_1 = nn.ConvTranspose2d(32, 16, 3, 2)\n",
    "\n",
    "        self.conv4_2 = ConvBlock(32, 16, 3, 1)\n",
    "        self.deconv5_1 = nn.ConvTranspose2d(16, 8, 3, 2)\n",
    "\n",
    "        self.conv5_2 = ConvBlock(16, 8, 3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.conv1_1(x)\n",
    "        print(x0.shape)\n",
    "        x = self.conv1_2(x0)\n",
    "        x1 = self.conv2_1(x)\n",
    "        x = self.conv2_2(x)\n",
    "        out0 = self.conv3_1(x)\n",
    "        x = self.deconv4_1(out0)\n",
    "\n",
    "        x = torch.cat([x1, x], dim=1)\n",
    "        out1 = self.conv4_2(x)\n",
    "        x = self.deconv5_1(out1)\n",
    "        x = torch.cat([x0, x], dim=1)\n",
    "\n",
    "        out2 = self.conv5_2(x)\n",
    "        return out0, out1, out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_in = torch.rand(8, 3, H, W)\n",
    "print(fake_in.shape)\n",
    "\n",
    "feat_worker = FeatureExtractor()\n",
    "\n",
    "output = feat_worker(fake_in)\n",
    "\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from image_utils import Random_Transforms\n",
    "\n",
    "basedir='/mnt/wmy/sport_1_mask'\n",
    "cam_id=0\n",
    "\n",
    "poses = np.loadtxt(os.path.join(basedir,'CamPose.inf'))\n",
    "Ks = read_intrinsics(os.path.join(basedir,'Intrinsic.inf'))\n",
    "\n",
    "img_fp = os.path.join(basedir, 'img', '%d/img_%04d.jpg' % (_FRAME_ID, cam_id))\n",
    "img = imageio.imread(img_fp)\n",
    "mask_fp = os.path.join(basedir, 'img', 'mask', '%d/img_%04d.jpg' % (_FRAME_ID, cam_id))\n",
    "mask = imageio.imread(mask_fp)\n",
    "\n",
    "img, K, img_mask, ROI = transform(img, Ks[cam_id], mask)\n",
    "\n",
    "print(img.shape)\n",
    "\n",
    "print(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "img_fp = os.path.join(basedir, 'img', '%d/img_%04d.jpg' % (0, 0))\n",
    "img = imageio.imread(img_fp)\n",
    "\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Ks[0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.remove('/usr/bin/python3.6')\n",
    "sys.path.append('/root/anaconda3/envs/sofgan/bin/python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/anaconda3/envs/sofgan/bin/python'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122, 256)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.latent_codes.weight.data.cpu().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anpei/anaconda3/envs/srns/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# That's an impressive list of imports.\n",
    "import numpy as np\n",
    "from numpy import linalg\n",
    "from numpy.linalg import norm\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "\n",
    "# We import sklearn.\n",
    "import sklearn\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "# We'll hack a bit with the t-SNE code in sklearn 0.15.2.\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.manifold.t_sne import (_joint_probabilities,\n",
    "                                    _kl_divergence)\n",
    "\n",
    "# Random state.\n",
    "RS = 20150101\n",
    "\n",
    "# We'll use matplotlib for graphics.\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "# We import seaborn to make nice plots.\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_palette('muted')\n",
    "sns.set_context(\"notebook\", font_scale=1.5,\n",
    "                rc={\"lines.linewidth\": 2.5})\n",
    "\n",
    "# We'll generate an animation with matplotlib and moviepy.\n",
    "from moviepy.video.io.bindings import mplfig_to_npimage\n",
    "import moviepy.editor as mpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection = TSNE(random_state=RS).fit_transform(model.latent_codes.weight.data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projection.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "palette = np.array(sns.color_palette(\"hls\", 10))\n",
    "\n",
    "# We create a scatter plot.\n",
    "f = plt.figure(figsize=(8, 8))\n",
    "ax = plt.subplot(aspect='equal')\n",
    "sc = ax.scatter(projection[:,0], projection[:,1], lw=0, s=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "linspace(): argument 'start' (position 1) must be Number, not Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7bffddf09621>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: linspace(): argument 'start' (position 1) must be Number, not Tensor"
     ]
    }
   ],
   "source": [
    "a, b = torch.zeros(2), torch.ones(2)\n",
    "torch.linspace(a,b,steps=6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
