{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys,os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from modeling import SOFModel\n",
    "import util\n",
    "from sklearn import mixture\n",
    "\n",
    "_RENDERER = 'FC'\n",
    "_ORTHO = False\n",
    "\n",
    "_MODEL_PATH = '/home/anpei/liury/log/SOF/092303face_seg_real_hidden3/checkpoints/epoch_0100_iter_020000.pth'\n",
    "# _MODEL_PATH = '../log/080320new_lstm/checkpoints//epoch_0184_iter_090000.pth'\n",
    "_OPT_CAM = False\n",
    "_ORTHO = True\n",
    "_TOT_NUM_INSTANCES = 221\n",
    "\n",
    "_IMG_SIZE = 128\n",
    "_OUT_SIZE = 128\n",
    "\n",
    "model = SOFModel(num_instances=_TOT_NUM_INSTANCES,\n",
    "                  latent_dim=256,\n",
    "                  renderer=_RENDERER,\n",
    "                  tracing_steps=10,\n",
    "                  freeze_networks=True,\n",
    "                  out_channels=20,\n",
    "                  img_sidelength=_IMG_SIZE,\n",
    "                  output_sidelength=_OUT_SIZE,\n",
    "                  opt_cam=_OPT_CAM,\n",
    "                  orthogonal=_ORTHO,\n",
    "                 )\n",
    "\n",
    "util.custom_load(model, path=_MODEL_PATH, discriminator=None,\n",
    "                 overwrite_embeddings=False, overwrite_cam=True)\n",
    "\n",
    "model.eval()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _CMAP = np.asarray([[0, 0, 0], [204, 0, 0], [76, 153, 0], [204, 204, 0], [51, 51, 255], [204, 0, 204], [0, 255, 255], [255, 204, 204], [102, 51, 0], \n",
    "#                     [255, 0, 0], [102, 204, 0], [255, 255, 0], [0, 0, 153], [0, 0, 204], [255, 51, 153], [0, 204, 204], [0, 51, 0], [255, 153, 51], [0, 204, 0], [0, 204, 153]]).astype(np.float32) / 255.0\n",
    "\n",
    "\n",
    "_CMAP = np.asarray([[0, 0, 0], [127, 212, 255], [255, 255, 127], [255, 255, 127], # 'background','skin', 'l_brow', 'r_brow'\n",
    "                    [255, 255, 170], [255, 255, 170], [240, 157, 240], [255, 212, 255], #'l_eye', 'r_eye', 'r_nose', 'l_nose',\n",
    "                    [31, 162, 230], [127, 255, 255], [127, 255, 255], #'mouth', 'u_lip', 'l_lip'\n",
    "                    [0, 255, 85], [0, 255, 85], [0, 255, 170], [255, 255, 170], #'l_ear', 'r_ear', 'ear_r', 'eye_g'\n",
    "                    [127, 170, 255], [85, 0, 255], [255, 170, 127], #'neck', 'neck_l', 'cloth'\n",
    "                    [212, 127, 255], [0, 170, 255]#, 'hair', 'hat'\n",
    "                    ])\n",
    "\n",
    "# _CMAP = np.asarray([[0, 0, 0], [204, 0, 0], [76, 153, 0], [204, 204, 0], [51, 51, 255], [204, 0, 204], [0, 255, 255], [255, 204, 204], [102, 51, 0], \n",
    "#                     [255, 0, 0], [102, 204, 0], [255, 255, 0], [0, 0, 153], [0, 0, 204], [255, 51, 153], [0, 204, 204], [0, 51, 0], [255, 153, 51], [0, 204, 0], [0, 204, 153]])\n",
    "\n",
    "_CMAP =torch.tensor(_CMAP, dtype=torch.float32) / 255.0\n",
    "\n",
    "\n",
    "\n",
    "# _CMAP = plt.get_cmap('gist_rainbow', 20)(range(20))[:, :3]\n",
    "\n",
    "#['background'0,'skin'1, 'l_brow'2, 'r_brow'2, 'l_eye'3, 'r_eye'3,'r_nose'4, 'l_nose'5, 'mouth'6, 'u_lip'7,\n",
    "# 'l_lip'8, 'l_ear'9, 'r_ear'9, 'ear_r'10, 'eye_g'11, 'neck'12, 'neck_l'13, 'cloth'14, 'hair'15, 'hat'16]\n",
    "# _LABEL = ['background', 'skin', 'brow', 'eye', \n",
    "#           'r_nose', 'l_nose', 'mouth', 'u_lip', 'l_lip', \n",
    "#           'ear', 'ear_ring', 'eye_glasses', 'neck', \n",
    "#           'necklace', 'cloth', 'hair', 'hat']\n",
    "# _OPA_BIAS = (np.array([0, 9, 10, 11, 12, 13, 14, 15, 16, 8, 7, 6, 5, 4, 3, 2, 1]) * 10.0).astype(int)\n",
    "\n",
    "\n",
    "_LABEL = ['background', 'skin', 'l_brow', 'r_brow', 'l_eye', 'r_eye','r_nose', 'l_nose', 'mouth', 'u_lip',\n",
    "'l_lip', 'l_ear', 'r_ear', 'ear_r', 'eye_g', 'neck', 'neck_l', 'cloth', 'hair', 'hat']\n",
    "\n",
    "\n",
    "# _OPA_SCALE = [0.0, 0.75, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.75, 0.75, 0.75, 0.5, 0.75, 0.75, 0.25, 0.5 ]\n",
    "_OPA_BIAS = (np.array([0, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 6, 5, 4, 3, 9, 2, 7, 8, 1]) * 10.0).astype(int)\n",
    "\n",
    "\n",
    "def _build_cam_int(focal, H, W):\n",
    "    return np.array([  [focal, 0., W // 2, 0.],\n",
    "                       [0., focal, H // 2, 0],\n",
    "                       [0., 0, 1, 0],\n",
    "                       [0, 0, 0, 1]])\n",
    "\n",
    "\n",
    "def render_scene(model, pose, z, focal, img_sidelength, dpt=None):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pose = torch.from_numpy(pose).float().unsqueeze(0)\n",
    "        cam_int = torch.from_numpy(\n",
    "            _build_cam_int(focal, _IMG_SIZE, _IMG_SIZE)).float().unsqueeze(0)\n",
    "\n",
    "        uv = np.mgrid[0:_IMG_SIZE, 0:_IMG_SIZE].astype(np.int32)\n",
    "        uv = torch.from_numpy(np.flip(uv, axis=0).copy()).long()\n",
    "        uv = uv.reshape(2, -1).transpose(1, 0).unsqueeze(0)\n",
    "\n",
    "        prob, depth_maps = model(pose, z, cam_int, uv, dpt=dpt)\n",
    "        pred = torch.argmax(prob, dim=2, keepdim=True)\n",
    "\n",
    "        prob = F.softmax(prob, dim=2)\n",
    "        \n",
    "#         print('*** prob = ', prob.shape, torch.max(prob))\n",
    "        \n",
    "        out_img = util.lin2img(pred, color_map=_CMAP).cpu().numpy()\n",
    "        out_seg = pred.view(img_sidelength, img_sidelength, 1).cpu().numpy()\n",
    "        \n",
    "        out_img = (out_img.squeeze().transpose(1, 2, 0)) * 255.0\n",
    "        out_img = out_img.round().clip(0, 255).astype(np.uint8)\n",
    "\n",
    "        out_seg = out_seg.squeeze().astype(np.uint8)\n",
    "        out_prob = prob.squeeze(0).view(\n",
    "            img_sidelength, img_sidelength, -1).cpu().numpy()\n",
    "        \n",
    "        return out_img, out_seg, out_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_idx = torch.randint(0, _TOT_NUM_INSTANCES, (1,)).squeeze().cuda()\n",
    "lat_idx = torch.IntTensor([98]).squeeze().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "lat_idx = torch.randint(0, _TOT_NUM_INSTANCES, (1,)).squeeze().cuda()\n",
    "latent = model.get_embedding({'instance_idx': lat_idx}).unsqueeze(0)\n",
    "\n",
    "_DEFAULT_CAM_INT = '../checkpoints/intrinsics.txt'\n",
    "cam_int = data_util.parse_intrinsics(_DEFAULT_CAM_INT, trgt_sidelength=128)\n",
    "focal = cam_int[0, 0]\n",
    "\n",
    "cam_center = np.asarray([0., 0.1, 0.1])\n",
    "cam_pose = _campos2matrix(np.array([0., 0.0, 1.0])+cam_center, cam_center)\n",
    "out_img, out_seg, _ = render_scene(model, cam_pose, latent, focal, _OUT_SIZE)\n",
    "\n",
    "l_nose_idx = np.asarray(np.where(out_seg==5))\n",
    "r_nose_idx = np.asarray(np.where(out_seg==4))\n",
    "nose_idx = np.concatenate([l_nose_idx, r_nose_idx], axis=1)        \n",
    "center = (np.mean(nose_idx[0]), np.mean(nose_idx[1]))\n",
    "\n",
    "yy = (_OUT_SIZE/2 - center[0])/(focal*4)\n",
    "xx = (center[1]-_OUT_SIZE/2)/(focal*4)\n",
    "\n",
    "cam_center = cam_center + np.array([xx, yy, 0.0])\n",
    "cam_pose = _campos2matrix(np.array([0., 0.0, 1.0])+cam_center, cam_center)\n",
    "\n",
    "out_img, out_seg, prob = render_scene(model, cam_pose, latent, focal, _OUT_SIZE)\n",
    "print(lat_idx, prob.shape)\n",
    "\n",
    "plt.axis('off')\n",
    "# plt.imshow(cv2.cvtColor(out_img, cv2.COLOR_BGR2RGB))\n",
    "plt.imshow(out_img)\n",
    "lat_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual, IntSlider, FloatSlider\n",
    "import ipywidgets as widgets\n",
    "\n",
    "def render_dpt(dpt, vis_cls):\n",
    "    out_img, out_seg, prob = render_scene(\n",
    "        model, cam_pose, latent, focal, _OUT_SIZE, dpt=dpt)\n",
    "    \n",
    "    figure=plt.figure(figsize=(10,5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(out_img)\n",
    "    plt.grid(\"off\");\n",
    "    plt.axis(\"off\");\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(_LABEL[vis_cls])\n",
    "    plt.imshow(prob[:, :, vis_cls], cmap=plt.get_cmap('magma'))\n",
    "    plt.grid(\"off\");\n",
    "    plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpt_range = [1.0, 1.75]\n",
    "\n",
    "dpt_slider = FloatSlider(min=dpt_range[0], max=dpt_range[1], step=0.005)\n",
    "cls_slider = IntSlider(min=0, max=len(_LABEL)-1, step=1, value=0)\n",
    "    \n",
    "interactive_plot = interactive(render_dpt, dpt=dpt_slider, vis_cls=cls_slider)\n",
    "output = interactive_plot.children[-1]\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set rgb map for volume rendering\n",
    "\n",
    "_CCMAP = _CMAP.cpu().numpy()\n",
    "if np.max(_CCMAP) > 1.0:\n",
    "    _CCMAP /= 255.0\n",
    "rgba_map = np.ones((200, 4))\n",
    "\n",
    "for idx, b_idx in enumerate(_OPA_BIAS):\n",
    "    s_idx = b_idx\n",
    "    cur_color = _CCMAP[idx]    \n",
    "    rgba_map[s_idx:(s_idx+10), :3] = cur_color\n",
    "    \n",
    "rgba_map[:10, 3] = 0\n",
    "rgba_map[10:, 3] = np.linspace(0, 0.05, rgba_map.shape[0]-10)\n",
    "\n",
    "print(rgba_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build density volume for interpolation\n",
    "\n",
    "import ipyvolume as ipv\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import cm\n",
    "\n",
    "_NUM_INTERPS = 10\n",
    "_NUM_SLICES = 128\n",
    "\n",
    "lat_idx = torch.randint(0, _TOT_NUM_INSTANCES, (2,)).squeeze().cuda()\n",
    "src_latent = model.get_embedding({'instance_idx': lat_idx[0]}).unsqueeze(0)\n",
    "trgt_latent = model.get_embedding({'instance_idx': lat_idx[1]}).unsqueeze(0)\n",
    "\n",
    "src_img, _, _ = render_scene(model, cam_pose, src_latent, focal, _OUT_SIZE)\n",
    "trgt_img, _, _ = render_scene(model, cam_pose, trgt_latent, focal, _OUT_SIZE)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.axis('off')\n",
    "plt.imshow(src_img)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.axis('off')\n",
    "plt.imshow(trgt_img)\n",
    "\n",
    "def set_vol_data(figure, framenr, fraction):\n",
    "#     fraction = 0.5\n",
    "    \n",
    "    latent = fraction*trgt_latent + (1.0 - fraction)*src_latent\n",
    "    full_prob = []\n",
    "\n",
    "    for dpt in np.linspace(dpt_range[0], dpt_range[1], _NUM_SLICES):\n",
    "        _, _, prob = render_scene(\n",
    "            model, cam_pose, latent, focal, _OUT_SIZE, dpt=dpt)\n",
    "        full_prob.append(np.expand_dims(prob, 0))\n",
    "\n",
    "    full_prob = np.concatenate(full_prob, axis=0)\n",
    "    cls_idx = np.argmax(full_prob, axis=-1).astype(int)\n",
    "    cls_prob = np.max(full_prob, axis=-1)\n",
    "\n",
    "    cls_prob = cls_prob + _OPA_BIAS[cls_idx]\n",
    "\n",
    "    ipv.figure()\n",
    "    ipv.style.axes_off()\n",
    "    ipv.style.box_off()\n",
    "    ipv.style.set_style_dark()\n",
    "    \n",
    "    vol_data = ipv.volshow(\n",
    "        np.flip(cls_prob, axis=1), tf=ipv.TransferFunction(rgba=rgba_map), \n",
    "        lighting=False, controls=True,\n",
    "        data_min=0.0, data_max=200)\n",
    "\n",
    "    vol_data.opacity_scale = 0.6\n",
    "    vol_data.brightness = 2.0\n",
    "\n",
    "    ipv.view(160, 0, 1.75)\n",
    "#     ipv.show()\n",
    "#     ipv.savefig('%02d.png'%(fraction*_NUM_INTERPS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create visualization volume\n",
    "import ipyvolume as ipv\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import cm\n",
    "\n",
    "# _OPA_BIAS = (np.array([0, 9, 10, 11, 12, 13, 14, 15, 16, 3, 5, 6, 7, 4, 8, 2, 1]) * 10.0).astype(int)\n",
    "\n",
    "_CCMAP = _CMAP.cpu().numpy()\n",
    "print('*** _CCMAP = ', _CCMAP.shape)\n",
    "\n",
    "if np.max(_CCMAP) > 1.0:\n",
    "    _CCMAP /= 255.0\n",
    "\n",
    "print(np.max(_CCMAP), lat_idx-1)\n",
    "\n",
    "rgba_map = np.ones((200, 4))\n",
    "\n",
    "for idx, b_idx in enumerate(_OPA_BIAS):\n",
    "    s_idx = b_idx\n",
    "    cur_color = _CCMAP[idx]    \n",
    "    rgba_map[s_idx:(s_idx+10), :3] = cur_color\n",
    "\n",
    "# print('*** rgba_map = ', rgba_map)\n",
    "# rgba_map = plt.get_cmap('rainbow', 200)(range(200))\n",
    "rgba_map[:10, 3] = 0\n",
    "rgba_map[10:, 3] = np.linspace(0, 0.05, rgba_map.shape[0]-10)\n",
    "\n",
    "full_prob = []\n",
    "\n",
    "for dpt in np.linspace(dpt_range[0], dpt_range[1], 128):\n",
    "    _, _, prob = render_scene(\n",
    "        model, cam_pose, latent, focal, _OUT_SIZE, dpt=dpt)\n",
    "    \n",
    "    full_prob.append(np.expand_dims(prob, 0))\n",
    "\n",
    "full_prob = np.concatenate(full_prob, axis=0)\n",
    "cls_idx = np.argmax(full_prob, axis=-1).astype(int)\n",
    "cls_prob = np.max(full_prob, axis=-1)\n",
    "\n",
    "print('*** cls_prob = ', np.max(cls_prob))\n",
    "\n",
    "cls_prob = cls_prob + _OPA_BIAS[cls_idx]\n",
    "\n",
    "\n",
    "# out = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "# with out:\n",
    "ipv.figure()\n",
    "ipv.style.axes_off()\n",
    "ipv.style.box_off()\n",
    "ipv.style.set_style_dark()\n",
    "\n",
    "vol_data = ipv.volshow(\n",
    "    np.flip(cls_prob, axis=1), \n",
    "    tf=ipv.TransferFunction(rgba=rgba_map), \n",
    "    lighting=False, controls=True,\n",
    "    data_min=0.0, data_max=200)\n",
    "\n",
    "vol_data.opacity_scale = 0.6\n",
    "vol_data.brightness = 2.0\n",
    "\n",
    "ipv.view(160, 0, 1.75)\n",
    "ipv.show()\n",
    "\n",
    "# ipv.savefig('test_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create visualization volume\n",
    "import ipyvolume as ipv\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import cm\n",
    "\n",
    "_CCMAP = _CMAP.cpu().numpy()\n",
    "\n",
    "cls_idx = 8\n",
    "\n",
    "if np.max(_CCMAP) > 1.0:\n",
    "    _CCMAP /= 255.0\n",
    "\n",
    "print(np.max(_CCMAP), lat_idx-1)\n",
    "\n",
    "rgba_map = np.stack([\n",
    "        np.linspace(0.0, _CCMAP[cls_idx][0], 200), \n",
    "        np.linspace(0.0, _CCMAP[cls_idx][1], 200), \n",
    "        np.linspace(0.0, _CCMAP[cls_idx][2], 200),\n",
    "        np.ones(200)\n",
    "    ]).T\n",
    "\n",
    "print('rgba_map = ', rgba_map.shape)\n",
    "\n",
    "# rgba_map = plt.get_cmap('rainbow', 200)(range(200))\n",
    "rgba_map[:, 3] = np.linspace(0, 0.1, rgba_map.shape[0])\n",
    "\n",
    "full_prob = []\n",
    "\n",
    "for dpt in np.linspace(0.8, 1.1, 128):\n",
    "    _, _, prob = render_scene(\n",
    "        model, cam_pose, latent, focal, _OUT_SIZE, dpt=dpt)\n",
    "\n",
    "    full_prob.append(np.expand_dims(prob, 0))\n",
    "\n",
    "full_prob = np.concatenate(full_prob, axis=0)\n",
    "print(full_prob.shape)\n",
    "\n",
    "\n",
    "# with out:\n",
    "ipv.figure()\n",
    "ipv.style.axes_off()\n",
    "ipv.style.box_off()\n",
    "ipv.style.set_style_dark()\n",
    "\n",
    "vol_data = ipv.volshow(\n",
    "    np.flip(full_prob[:, :, :, cls_idx], axis=1), \n",
    "    tf=ipv.TransferFunction(rgba=rgba_map), \n",
    "    lighting=False, controls=True,\n",
    "    data_min=0.0, data_max=1.0)\n",
    "\n",
    "vol_data.opacity_scale = 0.4\n",
    "vol_data.brightness = 2.0\n",
    "\n",
    "ipv.view(205, 10, 2.25)\n",
    "ipv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyvolume as ipv\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import cm\n",
    "\n",
    "\n",
    "for part in ['brow', \n",
    "             'skin', \n",
    "             'mouth',\n",
    "             'eye_glasses']:\n",
    "\n",
    "    ipv.figure()\n",
    "    ipv.style.axes_off()\n",
    "    ipv.style.box_off()\n",
    "    ipv.style.set_style_dark()\n",
    "    \n",
    "    vol_data = ipv.volshow(\n",
    "        vol_prob[part]['data'], \n",
    "        tf=ipv.TransferFunction(rgba=vol_prob[part]['cmap']), \n",
    "        lighting=False)\n",
    "    \n",
    "    ipv.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
